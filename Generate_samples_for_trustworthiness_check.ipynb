{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce24142d",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7c1b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import os.path as osp\n",
    "import sys\n",
    "import math\n",
    "import copy \n",
    "import pprint\n",
    "import shutil\n",
    "\n",
    "from tqdm import tqdm\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "import copy\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import imgaug.augmenters as iaa\n",
    "from PIL import Image\n",
    "from sklearn import manifold, datasets\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "from scipy.special import expit\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as T\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.models import resnet152, densenet121, mobilenet_v2\n",
    "\n",
    "import SimpleITK as sitk\n",
    "\n",
    "\n",
    "# from DiffableMaps import ExpModel\n",
    "from integrated_gradients import IntegratedGradients\n",
    "from xrai import XRAI\n",
    "from utils import *\n",
    "from ExplModel import *\n",
    "from attack import attack_expl_T, attack_pred_T\n",
    "\n",
    "# from utils import ShowImage, ShowHeatMap\n",
    "# from utils import get_expl, plot_overview, clamp, load_image, make_dir, img_norm\n",
    "# from chexpert import fetch_dataloader, grad_cam, DenseNet\n",
    "from dataset import ChexpertSmall\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de480785",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random seeds\n",
    "cudnn.benchmark = True\n",
    "manual_seed = 41\n",
    "random.seed(manual_seed)\n",
    "np.random.seed(manual_seed)\n",
    "torch.manual_seed(manual_seed)\n",
    "torch.cuda.manual_seed(manual_seed)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc8a028",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38723ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfgs = {}\n",
    "### model # (densenet121, resnet152, mobilenet_v2, efficientnet-b[0-7])')\n",
    "# ['VanillaBP', 'VanillaBP_Img', 'GuidedBP', 'IntegratedBP', 'GradCAM', 'GuidedGradCAM', 'SmoothBP', 'XRAI']\n",
    "dense121_cfgs = {\n",
    "    'model_info':{\n",
    "        'model_name': 'densenet121',\n",
    "        'model_path': '/home/Attack_Attn/ChestXpert/save_dir_multimodel/densenet121_5c/best_checkpoints/checkpoint_9.pt',\n",
    "#         'model_path': '/home/Attack_Attn/ChestXpert/save_dir_multimodel/densenet121_weakrobust/best_checkpoints/checkpoint_9.pt',\n",
    "#         'model_path': '/home/Attack_Attn/ChestXpert/save_dir_multimodel/robust_densenet121/best_checkpoints/checkpoint_9.pt',\n",
    "    },\n",
    "    'exp_method': 'VanillaBP',\n",
    "    'exp_cfgs':{\n",
    "#         'target_layer': ['features','denseblock4','denselayer14'],\n",
    "    }\n",
    "}\n",
    "# res152_cfgs = {\n",
    "#     'model_info':{\n",
    "#         'model_name': 'resnet152',\n",
    "#         'model_path': '/home/Attack_Attn/ChestXpert/save_dir_multimodel/resnet152_5c/best_checkpoints/checkpoint_5.pt',\n",
    "#     },\n",
    "#     'exp_method': 'IntegratedBP',\n",
    "#     'exp_cfgs':{\n",
    "# #         'target_layer': ['layer4','2'],\n",
    "#     }\n",
    "# }\n",
    "# mobilV2_cfgs = {\n",
    "#     'model_info':{\n",
    "#         'model_name': 'mobilenet_v2',\n",
    "#         'model_path': '/home/Attack_Attn/ChestXpert/save_dir_multimodel/mobilenet_v2_5c/best_checkpoints/checkpoint_7.pt',\n",
    "#     },\n",
    "#     'exp_method': 'IntegratedBP',\n",
    "#     'exp_cfgs':{\n",
    "# #         'target_layer': ['features', '17'],\n",
    "#     }\n",
    "# }\n",
    "\n",
    "model_cfgs = {}\n",
    "model_cfgs['src_models']=[\n",
    "    dense121_cfgs,\n",
    "#     mobilV2_cfgs,\n",
    "#     res152_cfgs,\n",
    "]\n",
    "model_cfgs['tgt_models']=[\n",
    "#     res152_cfgs,\n",
    "]\n",
    "model_cfgs['pretrained'] = False\n",
    "cfgs['model'] = model_cfgs\n",
    "\n",
    "\n",
    "### data\n",
    "data_cfgs = {}\n",
    "data_cfgs['data_path'] = '/home/Attack_Attn/ChestXpert/'\n",
    "data_cfgs['resize'] = 512\n",
    "data_cfgs['data_mean'] = np.array([0.5330])\n",
    "data_cfgs['data_std'] = np.array([0.0349])\n",
    "data_cfgs['mini_data'] = None\n",
    "data_cfgs['drop_lateral'] = True ## discard images with lateral view\n",
    "data_cfgs['n_classes'] = len(ChexpertSmall.attr_names)\n",
    "cfgs['dataset'] = data_cfgs\n",
    "\n",
    "# att\n",
    "att_cfgs = {}\n",
    "att_cfgs['num_iter'] = 1000\n",
    "att_cfgs['lr'] = 2e-4\n",
    "att_cfgs['output_dir'] = './save_dir'\n",
    "att_cfgs['epsilon'] = 0.03\n",
    "att_cfgs['start_beta'] = None\n",
    "att_cfgs['end_beta'] = None\n",
    "att_cfgs['beta_growth'] = False\n",
    "att_cfgs['prefactors'] = [8e4, 1e1]\n",
    "cfgs['attack'] = att_cfgs\n",
    "\n",
    "# att_cfgs = {}\n",
    "# att_cfgs['num_iter'] = 1000\n",
    "# att_cfgs['lr'] = 2e-4\n",
    "# att_cfgs['output_dir'] = './save_dir'\n",
    "# # att_cfgs['beta'] = 1000\n",
    "# att_cfgs['epsilon'] = 0.03\n",
    "# att_cfgs['start_beta'] = 10 #None\n",
    "# att_cfgs['end_beta'] = 100 #None\n",
    "# att_cfgs['beta_growth'] = True #False\n",
    "# # att_cfgs['prefactors'] = [1e6, 1] # [1e13, 1e2]\n",
    "# # att_cfgs['prefactors'] = [1e10, 0] # [1e13, 1e2]\n",
    "# # att_cfgs['prefactors'] = [1e10, 1] # [1e13, 1e2]\n",
    "# att_cfgs['prefactors'] = [1e14, 1e4] #[8e4, 1e1] # [1e13, 1e2]\n",
    "# # att_cfgs['prefactors'] = [8e11, 1e8] # [1e13, 1e2]\n",
    "# cfgs['attack'] = att_cfgs\n",
    "\n",
    "\n",
    "cfgs['device'] = 'cuda'\n",
    "cfgs['batch_size'] = 1\n",
    "### save\n",
    "cfgs['output_dir'] = '/data/users/Attack_Attn/save_dir/NatComm/attack_pred'\n",
    "os.makedirs(cfgs['output_dir'], exist_ok=True)\n",
    "\n",
    "cfgs['restore'] = ''\n",
    "cfgs['step'] = 0 \n",
    "\n",
    "# visualize and save expl maps\n",
    "cfgs['expl_vis'] = True\n",
    "cfgs['expl_save'] = True\n",
    "cfgs['expl_save_path'] = './save_dir'\n",
    "os.makedirs(cfgs['expl_save_path'], exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44cdca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfgs['model']['tgt_models'][0]['model_info']['model_path']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62c020b",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d336062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boilerplate methods.\n",
    "def ShowImage(im, title='', ax=None):\n",
    "    if ax is None:\n",
    "        plt.figure()\n",
    "#     plt.axis('off')\n",
    "    plt.imshow(im)\n",
    "    plt.title(title)\n",
    "    \n",
    "def ShowGrayscaleImage(im, title='', ax=None):\n",
    "    if ax is None:\n",
    "        plt.figure()\n",
    "#     plt.axis('off')\n",
    "    plt.imshow(im, cmap=plt.cm.gray, vmin=0, vmax=1)\n",
    "    plt.title(title)\n",
    "    \n",
    "def ShowHeatMap(im, title, ax=None):\n",
    "    if ax is None:\n",
    "        plt.figure()\n",
    "#     plt.axis('off')\n",
    "    plt.imshow(im, cmap='inferno')\n",
    "    plt.title(title)\n",
    "    \n",
    "def clamp(x, mean, std):\n",
    "    upper = torch.from_numpy(np.array((1.0 - mean) / std)).to(x.device)\n",
    "    lower = torch.from_numpy(np.array((0.0 - mean) / std)).to(x.device)\n",
    "\n",
    "    if x.shape[1] == 3:  # 3-channel image\n",
    "        for i in [0, 1, 2]:\n",
    "            x[0][i] = torch.clamp(x[0][i], min=lower[i], max=upper[i])\n",
    "    else:\n",
    "        x = torch.clamp(x, min=lower[0], max=upper[0])\n",
    "    return x\n",
    "\n",
    "def load_image_view(data_mean, data_std, image):\n",
    "    transforms_org = T.Compose([\n",
    "        T.Resize(data_cfgs['resize']),\n",
    "        T.CenterCrop(data_cfgs['resize']),\n",
    "        T.ToTensor(),\n",
    "#         T.Lambda(lambda x: torch.from_numpy(np.array(x, copy=True)).float().div(255)),   # tensor in [0,1]\n",
    "        T.Lambda(lambda x: x.expand(3,-1,-1))\n",
    "    ])\n",
    "    transforms_pred = T.Compose([\n",
    "        T.Resize(data_cfgs['resize']),\n",
    "        T.CenterCrop(data_cfgs['resize']),\n",
    "        T.ToTensor(),\n",
    "#         T.Lambda(lambda x: torch.from_numpy(np.array(x, copy=True)).float().div(255)),   # tensor in [0,1]\n",
    "        T.Normalize(mean=data_mean, std=data_std),\n",
    "        T.Lambda(lambda x: x.expand(3,-1,-1))\n",
    "    ])\n",
    "    if data_mean is not None and data_std is not None:\n",
    "        img_ = transforms_pred(image).permute(1,2,0)\n",
    "    else:\n",
    "        img_ = transforms_org(image).permute(1,2,0)\n",
    "    return img_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3f8d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''load image for momdel input'''\n",
    "def get_transforms(data_cfgs, if_norm=False, aug=None):\n",
    "    transforms = [\n",
    "#         T.Resize((data_cfgs['resize'], data_cfgs['resize']))\n",
    "        T.Resize(data_cfgs['resize']),\n",
    "        T.CenterCrop(data_cfgs['resize']),\n",
    "    ]\n",
    "    \n",
    "    if aug is not None:\n",
    "        transforms += [\n",
    "            T.Lambda(aug),\n",
    "            T.CenterCrop(data_cfgs['resize']),\n",
    "            T.RandomHorizontalFlip(),\n",
    "        ]\n",
    "    if if_norm:\n",
    "        transforms += [\n",
    "            T.Normalize(mean=data_cfgs['data_mean'], std=data_cfgs['data_std'])\n",
    "        ]\n",
    "        \n",
    "    transforms.append(T.ToTensor())\n",
    "    return T.Compose(transforms)\n",
    "\n",
    "def image_process(image, data_cfgs, if_norm=False, aug=None):\n",
    "    transforms = get_transforms(data_cfgs, if_norm, aug)\n",
    "    return transforms(image)\n",
    "\n",
    "\n",
    "# '''load image for visualization'''\n",
    "# def image_process_vis(image, data_cfgs, if_norm=False, aug=None):\n",
    "#     return image_process(image, data_cfgs, if_norm, aug).expand(3,-1,-1).permute(1,2,0).contiguous()\n",
    "\n",
    "\n",
    "def img_norm(image, k=1):\n",
    "    if isinstance(image, np.ndarray):\n",
    "        image = image.astype('float')\n",
    "    else:\n",
    "        image = image.to(torch.float32)\n",
    "    image = image - image.min()\n",
    "    image = image / image.max()\n",
    "    if isinstance(image, np.ndarray):\n",
    "        image = np.clip(image*k, 0, 1)\n",
    "    else:\n",
    "        image = torch.clip(image*k, 0, 1)\n",
    "    return image\n",
    "\n",
    "\n",
    "def batch_img_norm(image, k=1):\n",
    "    if isinstance(image, np.ndarray):\n",
    "        image = image.astype('float')\n",
    "        n, h, w = image.shape\n",
    "        image = image.reshape(n, -1)\n",
    "        image = image - image.min(axis=1, keepdims=True)\n",
    "        image = image / (image.max(axis=1, keepdims=True) + 1e-10)\n",
    "        image = np.clip(image*k, 0, 1)\n",
    "        image = image.reshape(n, h, w)\n",
    "    else:\n",
    "        image = image.to(torch.float32)\n",
    "        n, h, w = image.size()\n",
    "        image = image.view(n, -1)\n",
    "        image = image - image.min(dim=1, keepdim=True)\n",
    "        image = image / (image.max(dim=1, keepdim=True) + 1e-10)\n",
    "        image = torch.clip(image*k, 0, 1)\n",
    "        image = image.view(n, h, w)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42939fb4",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2014d6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''data augmentation'''\n",
    "class Augmenter(object):\n",
    "    def __init__(self):\n",
    "        self.aug_seq = iaa.Sequential([\n",
    "            iaa.AdditiveGaussianNoise(scale=(0.0*255, 0.02*255), per_channel=True),\n",
    "#             iaa.GaussianBlur(sigma=(0.0, 1.0))\n",
    "        ])\n",
    "    def __call__(self, img):\n",
    "        img = np.asarray(img)\n",
    "        aug_img = self.aug_seq(image=img)\n",
    "        aug_img = Image.fromarray(aug_img)\n",
    "        return aug_img\n",
    "    \n",
    "AUGMENT = Augmenter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fb30de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_dataloader(cfgs, mode):\n",
    "    assert mode in ['train', 'valid', 'test', 'vis']\n",
    "    data_cfgs = cfgs['dataset']\n",
    "    if mode == 'train':\n",
    "        transforms = get_transforms(data_cfgs, aug=AUGMENT)\n",
    "    else:\n",
    "        transforms = get_transforms(data_cfgs)\n",
    "        \n",
    "    dataset = ChexpertSmall(\n",
    "        data_cfgs['data_path'],\n",
    "        mode, transforms, \n",
    "        mini_data=data_cfgs['mini_data'], \n",
    "        drop_lateral=data_cfgs['drop_lateral'])\n",
    "    \n",
    "    return DataLoader(\n",
    "        dataset, cfgs['batch_size'],\n",
    "        shuffle=(mode=='train'),\n",
    "        pin_memory=(cfgs['device']=='cuda'),\n",
    "        num_workers=0 if mode=='valid' else 16) \n",
    "# since evaluating the valid_dataloader is called inside the\n",
    "# train_dataloader loop, 0 workers for valid_dataloader avoids\n",
    "# forking (cf torch dataloader docs); else memory sharing gets clunky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0c1889",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_dataloader = fetch_dataloader(cfgs, mode='train')\n",
    "valid_dataloader = fetch_dataloader(cfgs, mode='valid')\n",
    "\n",
    "print('Attributes: ', valid_dataloader.dataset.attr_names)\n",
    "print('Num classes:', len(valid_dataloader.dataset.attr_names))\n",
    "print('Train data length: ', len(train_dataloader.dataset))\n",
    "print('Valid data length: ', len(valid_dataloader.dataset))\n",
    "\n",
    "batch_datas, batch_labels, batch_index = next(iter(train_dataloader)) \n",
    "print('label:', batch_labels[0:5])\n",
    "\n",
    "# print images\n",
    "plt.figure(figsize=(6,6))\n",
    "img = make_grid(batch_datas[:32], nrow=8, padding=2)\n",
    "npimg = img.numpy()\n",
    "print(npimg.shape)\n",
    "plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n",
    "\n",
    "# batch size\n",
    "print(batch_datas.size(), batch_datas.max(), batch_datas.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be84e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_labels = batch_labels.to(torch.device(cfgs['device']))\n",
    "# batch_labels.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbeea29",
   "metadata": {},
   "source": [
    "# Train & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e241f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_single_model(model, dataloader, loss_fn, cfgs):\n",
    "    outputs, targets, losses = evaluate(model, dataloader, loss_fn, cfgs)\n",
    "    return compute_metrics(outputs, targets, losses)\n",
    "    \n",
    "    \n",
    "def evaluate(model, dataloader, loss_fn, cfgs):\n",
    "    model.eval()\n",
    "    targets, outputs, losses = [], [], []\n",
    "    index = 0\n",
    "    for x, target, idxs in dataloader:\n",
    "        index+=1\n",
    "#         if index<30:\n",
    "        out = model(x.cuda())\n",
    "#             print(out)\n",
    "        loss = loss_fn(out, target.cuda())\n",
    "        outputs += [out.cpu()]\n",
    "        targets += [target]\n",
    "        losses  += [loss.cpu()]\n",
    "    return torch.cat(outputs), torch.cat(targets), torch.cat(losses)\n",
    "\n",
    "\n",
    "def compute_metrics(outputs, targets, losses):\n",
    "    n_classes = outputs.shape[1]\n",
    "    fpr, tpr, aucs, precision, recall = {}, {}, {}, {}, {}\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(targets[:,i], outputs[:,i])\n",
    "        aucs[i] = auc(fpr[i], tpr[i])\n",
    "        precision[i], recall[i], _ = precision_recall_curve(targets[:,i], outputs[:,i])\n",
    "        fpr[i], tpr[i], precision[i], recall[i] = fpr[i].tolist(), tpr[i].tolist(), precision[i].tolist(), recall[i].tolist()\n",
    "\n",
    "    metrics = {'fpr': fpr,\n",
    "               'tpr': tpr,\n",
    "               'aucs': aucs,\n",
    "               'precision': precision,\n",
    "               'recall': recall,\n",
    "               'loss': dict(enumerate(losses.mean(0).tolist()))}\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5b0427",
   "metadata": {},
   "source": [
    "## Eval metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a530aaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_total(dataset, args, model_name='densenet'):\n",
    "    if model_name == 'densenet':\n",
    "        des_model = densenet121(pretrained=False)#.cuda()\n",
    "        des_model.classifier = nn.Linear(des_model.classifier.in_features, out_features=args['n_classes'])\n",
    "        checkpoint = torch.load(args['densenet_path'])\n",
    "        des_model.load_state_dict(checkpoint['state_dict'])\n",
    "        des_model.eval()\n",
    "    \n",
    "    ### init the lists for three metrics[method names]\n",
    "    targets, outputs_org, outputs_adv = [], [], []\n",
    "    tot_ssim_list, tot_mse_list, tot_pcc_list = {}, {}, {}\n",
    "    method_list = ['VanillaBP', 'VanillaBP_Img', 'GradCam', 'GuidedGradCam', 'IntegratedBP', 'SmoothBP', 'XRAI']\n",
    "    for method_name in method_list:\n",
    "        tot_ssim_list[method_name], tot_mse_list[method_name], tot_pcc_list[method_name] = [], [], []\n",
    "    \n",
    "    for image_index in np.arange(55): #np.arange(len(dataset)): #\n",
    "#         if image_index > 74:\n",
    "            print('============== image_index:', image_index, '=================\\n')\n",
    "            if image_index>-1:\n",
    "                _, target, _ = dataset[image_index]\n",
    "                target = target.unsqueeze(0)\n",
    "            '''three metrics'''\n",
    "            for method_name in method_list:\n",
    "                img_list, _, ssim_list, mse_list, pcc_list = ImgPairMetric(case_num=image_index, metric_name=method_name)\n",
    "                tot_ssim_list[method_name].append(ssim_list)\n",
    "                tot_mse_list[method_name].append(mse_list)\n",
    "                tot_pcc_list[method_name].append(pcc_list)\n",
    "            '''model performance (AUC, precision, ...)'''  \n",
    "            img_org0, img_adv0 = img_list\n",
    "            img_org0_ts = torch.Tensor(img_org0).permute(2,0,1).unsqueeze(0)\n",
    "            img_adv0_ts = torch.Tensor(img_adv0).permute(2,0,1).unsqueeze(0)\n",
    "            with torch.no_grad(): # run on cpu, no cuda\n",
    "                out_org, out_adv = des_model(img_org0_ts), des_model(img_adv0_ts)\n",
    "                outputs_org += [out_org]\n",
    "                outputs_adv += [out_adv]\n",
    "                targets += [target]\n",
    "    outputs_org, outputs_adv, targets, = torch.cat(outputs_org), torch.cat(outputs_adv), torch.cat(targets)\n",
    "    metrics_org, metrics_adv = compute_metrics(outputs_org, targets), compute_metrics(outputs_adv, targets)\n",
    "    return tot_ssim_list, tot_mse_list, tot_pcc_list, metrics_org, metrics_adv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08d9a17",
   "metadata": {},
   "source": [
    "# __Main__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adda430e",
   "metadata": {},
   "source": [
    "## Attack source model & save data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87652615",
   "metadata": {},
   "source": [
    "### Instantiation models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688e3919",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_exp_models = [expmodel_factory(model_cfgs, cfgs) for model_cfgs in cfgs['model']['src_models']]\n",
    "# target_exp_models = [expmodel_factory(model_cfgs, cfgs) for model_cfgs in cfgs['model']['tgt_models']]\n",
    "\n",
    "#  def __init__(self, cfgs, target_layer, init_from=None, model_info=None):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb72e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Attributes: ', valid_dataloader.dataset.attr_names)\n",
    "print('Num classes:', len(valid_dataloader.dataset.attr_names))\n",
    "print('Valid data length: ', len(valid_dataloader.dataset))\n",
    "\n",
    "img_idx = 160\n",
    "\n",
    "img, label, patient_id = valid_dataloader.dataset[img_idx]\n",
    "print('label:', label)\n",
    "print(img.size())\n",
    "\n",
    "class_of_interest = [1., 0., 0., 0., 0.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce786d5f",
   "metadata": {},
   "source": [
    "### Heatmap of one sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae539f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label, patient_id = valid_dataloader.dataset[img_idx]\n",
    "print('label:', label)\n",
    "print(img.size())\n",
    "\n",
    "res = [_.cal_exp_map(img.to(torch.device(cfgs['device'])).unsqueeze(0), class_of_interest) for _ in source_exp_models]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7e8213",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_of_interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa5d2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img.min(), img.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3104a650",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "if source_exp_models[0].exp_name == 'XRAI':\n",
    "    for heatmap, pred in res:\n",
    "        ROWS = 1\n",
    "        COLS = 3\n",
    "        UPSCALE_FACTOR = 20\n",
    "        plt.figure(figsize=(ROWS * UPSCALE_FACTOR, COLS * UPSCALE_FACTOR))\n",
    "        ##\n",
    "#         im_orig = load_image_view(data_mean=None, data_std=None, image=img)\n",
    "        im_orig = img.permute(1,2,0)\n",
    "        ## Show original image\n",
    "        ShowGrayscaleImage(im_orig, title='Original Image', ax=plt.subplot(ROWS, COLS, 1))\n",
    "        ## Show XRAI heatmap attributions\n",
    "        ShowHeatMap(heatmap, title='XRAI Heatmap', ax=plt.subplot(ROWS, COLS, 2))\n",
    "        ## Show most salient 30% of the image\n",
    "        mask = heatmap > np.percentile(heatmap, 92)\n",
    "        im_mask = np.array(im_orig)\n",
    "        im_mask[~mask] = 0\n",
    "        ShowImage(im_mask, title='Top 15%', ax=plt.subplot(ROWS, COLS, 3))\n",
    "else:       \n",
    "    for heatmap, pred in res:\n",
    "        print(torch.sigmoid(pred))\n",
    "        heatmap = heatmap.data.cpu().numpy()\n",
    "        heatmap = img_norm(heatmap,k=1.7) # norm grad to speial range\n",
    "        cmap = cm.jet_r(1-heatmap)[..., :3]     # color map proj\n",
    "        cmap = img_norm(cmap)                     # re-norm to [0,1]\n",
    "\n",
    "        ## load original image\n",
    "        base_img = img.expand(3,-1,-1).permute(1,2,0)\n",
    "        alpha = 0.5\n",
    "        img_fused = base_img*(1-alpha) + cmap*alpha\n",
    "        plt.figure(figsize=(6,6))\n",
    "        plt.imshow(img_fused[0])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e95d0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdecda4",
   "metadata": {},
   "source": [
    "### Attack one sample PRED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d500173",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' trun off the beta update scheduler '''\n",
    "att_cfgs = {}\n",
    "att_cfgs['num_iter'] = 8 # VBP:8 | VBP*I: 8 | IG: 20 | SG: 50  | GCAM:60\n",
    "att_cfgs['lr'] = 2e-4\n",
    "att_cfgs['output_dir'] = './save_dir'\n",
    "att_cfgs['epsilon'] = 0.03\n",
    "att_cfgs['start_beta'] = None\n",
    "att_cfgs['end_beta'] = None\n",
    "att_cfgs['beta_growth'] = False\n",
    "att_cfgs['prefactors'] = [8e4, 1e1]\n",
    "cfgs['attack'] = att_cfgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be27ffb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "''' targeted-logit attack'''\n",
    "img, label, patient_id = valid_dataloader.dataset[img_idx]\n",
    "print('label:', label)\n",
    "print(img.size())\n",
    "\n",
    "# adv_imgs = attack_pred_T(\n",
    "#     source_exp_models,\n",
    "#     img.to(torch.device(cfgs['device'])).unsqueeze(0),\n",
    "#     class_of_interest,\n",
    "#     label.to(torch.device(cfgs['device'])).unsqueeze(0),\n",
    "#     cfgs,\n",
    "# #     attack_steps=1000,\n",
    "# #     vis_iter=50\n",
    "# )\n",
    "\n",
    "adv_imgs = attack_pred_T_old(\n",
    "    source_exp_models,\n",
    "    img.to(torch.device(cfgs['device'])).unsqueeze(0),\n",
    "    class_of_interest,\n",
    "    label.to(torch.device(cfgs['device'])).unsqueeze(0),\n",
    "    cfgs,\n",
    "#     attack_steps=1000,\n",
    "#     vis_iter=50\n",
    ")\n",
    "\n",
    "print((img.cuda().unsqueeze(0)-adv_imgs).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfaa27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_exp_models = [expmodel_factory(model_cfgs, cfgs) for model_cfgs in cfgs['model']['src_models']]\n",
    "# target_exp_models = [expmodel_factory(model_cfgs, cfgs) for model_cfgs in cfgs['model']['tgt_models']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce1f76f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''--- evaluate on source model ---'''\n",
    "_img = adv_imgs.clone().detach()\n",
    "res = [_.cal_exp_map(_img, class_of_interest) for _ in source_exp_models]\n",
    "\n",
    "# img, label, patient_id = valid_dataloader.dataset[img_idx]\n",
    "# res = [_.cal_exp_map(img.to(torch.device(cfgs['device'])).unsqueeze(0), class_of_interest) for _ in source_exp_models]\n",
    "\n",
    "\n",
    "for heatmap, pred in res:\n",
    "    print(torch.sigmoid(pred))\n",
    "    heatmap = heatmap.data.cpu().numpy()\n",
    "    heatmap = img_norm(heatmap, k=1.7) # norm grad to speial range\n",
    "    cmap = cm.jet_r(1-heatmap)[..., :3]     # color map proj\n",
    "    cmap = img_norm(cmap)                     # re-norm to [0,1]\n",
    "    \n",
    "    ## load original image\n",
    "    base_img = _img[0].data.cpu().expand(3,-1,-1).permute(1,2,0)\n",
    "    alpha = .99\n",
    "    htmp_weight = np.zeros_like(cmap.squeeze())\n",
    "    print(htmp_weight.shape)\n",
    "    htmp_weight[:,:,0], htmp_weight[:,:,1], htmp_weight[:,:,2] = heatmap, heatmap, heatmap\n",
    "    img_fused = base_img*(1-htmp_weight) + cmap*alpha*htmp_weight\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    base_img = _img[0].data.cpu().expand(3,-1,-1).permute(1,2,0)\n",
    "    alpha = .5\n",
    "    img_fused = base_img*(1-alpha) + cmap*alpha\n",
    "    plt.subplot(2,2,1)\n",
    "    plt.imshow(img[0], cmap='gray')\n",
    "    plt.subplot(2,2,2)\n",
    "#     plt.imshow(attack_target_maps[0].data.cpu(), cmap='gray')\n",
    "    plt.subplot(2,2,3)\n",
    "    plt.imshow(_img[0,0].data.cpu().numpy(), cmap='gray')\n",
    "    plt.subplot(2,2,4)\n",
    "    plt.imshow(img_fused[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193bae52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (img[0] - _img[0,0].data.cpu()).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e64950",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''--- evaluate on target model ---'''\n",
    "# # 0.03\n",
    "# _img = adv_imgs.clone().detach()\n",
    "# res = [_.cal_exp_map(_img, class_of_interest) for _ in target_exp_models]\n",
    "\n",
    "# for heatmap, pred in res:\n",
    "#     print(torch.sigmoid(pred))\n",
    "#     heatmap = heatmap.data.cpu().numpy()\n",
    "#     heatmap = img_norm(heatmap) # norm grad to speial range\n",
    "#     cmap = cm.jet_r(1-heatmap)[..., :3]     # color map proj\n",
    "#     cmap = img_norm(cmap)                     # re-norm to [0,1]\n",
    "    \n",
    "#     ## load original image\n",
    "#     plt.figure(figsize=(10,10))\n",
    "#     base_img = _img[0].data.cpu().expand(3,-1,-1).permute(1,2,0)\n",
    "#     alpha = .5\n",
    "#     img_fused = base_img*(1-alpha) + cmap*alpha\n",
    "#     plt.subplot(2,2,1)\n",
    "#     plt.imshow(img[0], cmap='gray')\n",
    "#     plt.subplot(2,2,2)\n",
    "# #     plt.imshow(attack_target_maps[0].data.cpu(), cmap='gray')\n",
    "#     plt.subplot(2,2,3)\n",
    "#     plt.imshow(_img[0,0].data.cpu().numpy(), cmap='gray')\n",
    "#     plt.subplot(2,2,4)\n",
    "#     plt.imshow(img_fused[0])\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46b06c4",
   "metadata": {},
   "source": [
    "### Attack one sample EXPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35228480",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' trun on the beta update scheduler '''\n",
    "att_cfgs['start_beta'] = 10 #None\n",
    "att_cfgs['end_beta'] = 100 #None\n",
    "att_cfgs['beta_growth'] = True #False\n",
    "att_cfgs['num_iter'] = 200\n",
    "\n",
    "att_cfgs['prefactors'] = [1e14, 1e4] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c44e433",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label, patient_id = valid_dataloader.dataset[img_idx]\n",
    "print('label:', label)\n",
    "print(img.size())\n",
    "\n",
    "res = [_.cal_exp_map(img.to(torch.device(cfgs['device'])).unsqueeze(0), class_of_interest) for _ in source_exp_models]\n",
    "h_map = res[0][0]\n",
    "h_map = img_norm(h_map)\n",
    "attack_target_maps = 1-h_map\n",
    "attack_target_maps = img_norm(attack_target_maps)\n",
    "print(attack_target_maps.min(), attack_target_maps.max())\n",
    "print((1-attack_target_maps).min(), (1-attack_target_maps).max())\n",
    "plt.imshow(1-attack_target_maps[0].data.cpu())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28617be8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img, label, patient_id = valid_dataloader.dataset[img_idx]\n",
    "print('label:', label)\n",
    "print(img.size())\n",
    "\n",
    "attack_target_maps = torch.zeros_like(img).detach_()\n",
    "attack_target_maps[:, 130:190, 380:440] = 1.0/3600 # binary mask\n",
    "\n",
    "adv_imgs = attack_expl_T(\n",
    "    source_exp_models, \n",
    "    img.to(torch.device(cfgs['device'])).unsqueeze(0), \n",
    "    class_of_interest, \n",
    "    attack_target_maps.to(torch.device(cfgs['device'])).unsqueeze(0),\n",
    "    cfgs, \n",
    "    attack_steps=200,\n",
    "    epsilon=0.06,\n",
    "    vis_iter=40\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0877ab7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "source_exp_models = [expmodel_factory(model_cfgs, cfgs) for model_cfgs in cfgs['model']['src_models']]\n",
    "# target_exp_models = [expmodel_factory(model_cfgs, cfgs) for model_cfgs in cfgs['model']['tgt_models']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d0a295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.03\n",
    "_img = adv_imgs.clone().detach()\n",
    "res = [_.cal_exp_map(_img, class_of_interest) for _ in source_exp_models]\n",
    "# res_org = [_.cal_exp_map(img, class_of_interest) for _ in source_exp_models]\n",
    "\n",
    "for heatmap, _ in res:\n",
    "    print(torch.sigmoid(_))\n",
    "    print(torch.sigmoid(pred))\n",
    "    heatmap = heatmap.data.cpu().numpy()\n",
    "    heatmap = img_norm(heatmap,k=2.7) # norm grad to speial range\n",
    "#     heatmap = img_norm(heatmap) # norm grad to speial range\n",
    "    cmap = cm.plasma(heatmap)[..., :3]     # color map proj\n",
    "    cmap = img_norm(cmap)                     # re-norm to [0,1]\n",
    "    \n",
    "    ## load original image\n",
    "    plt.figure(figsize=(10,10))\n",
    "    base_img = _img[0].data.cpu().expand(3,-1,-1).permute(1,2,0)\n",
    "    alpha = .99\n",
    "    htmp_weight = np.zeros_like(cmap.squeeze())\n",
    "    print(htmp_weight.shape)\n",
    "    htmp_weight[:,:,0], htmp_weight[:,:,1], htmp_weight[:,:,2] = heatmap, heatmap, heatmap\n",
    "    \n",
    "    img_fused = base_img*(1-htmp_weight) + cmap*alpha*htmp_weight\n",
    "    plt.subplot(2,2,1)\n",
    "    plt.imshow(img[0], cmap='gray')\n",
    "    plt.subplot(2,2,2)\n",
    "    plt.imshow(attack_target_maps[0].data.cpu(), cmap='gray')\n",
    "    plt.subplot(2,2,3)\n",
    "    plt.imshow(_img[0,0].data.cpu().numpy(), cmap='gray')\n",
    "    plt.subplot(2,2,4)\n",
    "    plt.imshow(img_fused[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b50859",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = np.abs(_img[0,0].data.cpu().numpy() - img[0].data.cpu().numpy())\n",
    "print(diff.min(), diff.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2d16db",
   "metadata": {},
   "outputs": [],
   "source": [
    "_img = adv_imgs.clone().detach()\n",
    "# res = [_.cal_exp_map(_img, class_of_interest) for _ in target_exp_models]\n",
    "res = [_.cal_exp_map(_img, class_of_interest) for _ in source_exp_models]\n",
    "for heatmap, _ in res:\n",
    "    print(torch.sigmoid(pred))\n",
    "    heatmap = heatmap.data.cpu().numpy()\n",
    "    heatmap = img_norm(heatmap) # norm grad to speial range\n",
    "    cmap = cm.jet_r(1-heatmap)[..., :3]     # color map proj\n",
    "    cmap = img_norm(cmap)                     # re-norm to [0,1]\n",
    "    \n",
    "    ## load original image\n",
    "    plt.figure(figsize=(10,10))\n",
    "    base_img = _img[0].data.cpu().expand(3,-1,-1).permute(1,2,0)\n",
    "    alpha = .5\n",
    "    img_fused = base_img*(1-alpha) + cmap*alpha\n",
    "    plt.subplot(2,2,1)\n",
    "    plt.imshow(img[0], cmap='gray')\n",
    "    plt.subplot(2,2,2)\n",
    "    plt.imshow(attack_target_maps[0].data.cpu(), cmap='gray')\n",
    "    plt.subplot(2,2,3)\n",
    "    plt.imshow(_img[0,0].data.cpu().numpy(), cmap='gray')\n",
    "    plt.subplot(2,2,4)\n",
    "    plt.imshow(img_fused[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c783e74",
   "metadata": {},
   "source": [
    "### Test on target models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23871af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# img, label, patient_id = valid_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8160ac37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src_model = load_model(src_tgt='src', args=args)\n",
    "# src_model_name = 'densenet' if 'densenet' in args['src_model'] else 'resnet'\n",
    "\n",
    "# tgt_model = load_model(src_tgt='tgt', args=args)\n",
    "# tgt_model_name = 'densenet' if 'densenet' in args['tgt_model'] else 'resnet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228ae481",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ### define number of steps to attack\n",
    "# label_dict = {'0': [1., 0., 0., 0., 0.],\n",
    "#               '1': [0., 1., 0., 0., 0.],\n",
    "#               '2': [0., 0., 1., 0., 0.],\n",
    "#               '3': [0., 0., 0., 1., 0.],\n",
    "#               '4': [0., 0., 0., 0., 1.]}\n",
    "# args_att['num_iter'] = 40\n",
    "# SSIM = []\n",
    "\n",
    "# for image_index in np.arange(1): #len(ds)\n",
    "#     img, label, patient_id = ds[image_index]\n",
    "#     try: \n",
    "#         first_one_position = np.where(np.array(label) == 1)[0][0] ## first 1\n",
    "#     except: \n",
    "#         first_one_position = -1  ### no 1\n",
    "    \n",
    "#     if first_one_position>=0:\n",
    "#         label_list = label_dict[str(first_one_position)]\n",
    "        \n",
    "#         print('========== src attacked image {} ==========='.format(image_index))\n",
    "#         args['expl_vis'] = True\n",
    "#         x_adv, one_hot = AttackExpl(model_name=src_model_name, model=src_model, \n",
    "#                                    dataset=ds, image_index=image_index, label_list=label_list, \n",
    "#                                    method_name=method_name, args=args, args_att=args_att, args_method=None)\n",
    "        \n",
    "#         print('========== tgt original image {} ==========='.format(image_index))\n",
    "#         args['expl_vis'] = True\n",
    "#         G_org = GetExpl(model_name=tgt_model_name, model=tgt_model,\n",
    "#                         dataset=ds, image_index=image_index, label_list=label_list, \n",
    "#                         beta=None, method_name=method_name, args=args)\n",
    "\n",
    "#         print('========== tgt attacked image {} ==========='.format(image_index))\n",
    "#         G_att = GetExpl_from_image(model_name=tgt_model_name, model=tgt_model,\n",
    "#                                    image_ts=x_adv, one_hot=one_hot, \n",
    "#                                    method_name=method_name, args=args, beta=None, args_method=None)\n",
    "#         expl_ssim, _ = ssim(img_norm_02(G_org), img_norm_02(G_att), data_range=255, full=True, multichannel=False)\n",
    "#         SSIM.append(expl_ssim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20416606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SSIM_np=np.asarray(SSIM)\n",
    "# plt.hist(SSIM_np,50)\n",
    "# plt.xlabel('SSIM',fontsize=16)\n",
    "# plt.ylabel('Counts',fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c267d8",
   "metadata": {},
   "source": [
    "# __Test__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40a54f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = [1,2,3,4,1,2,3,4,1]\n",
    "for m in aa:\n",
    "    if m != 1: \n",
    "        continue\n",
    "    else: \n",
    "        m +=1\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fd0ead",
   "metadata": {},
   "source": [
    "## attack PRED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714782c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' trun off the beta update scheduler '''\n",
    "# att_cfgs['start_beta'] = None\n",
    "# att_cfgs['end_beta'] = None\n",
    "# att_cfgs['beta_growth'] = False\n",
    "# att_cfgs['num_iter'] = 4\n",
    "\n",
    "# att_cfgs['prefactors'] = [1, 8e14]#[8e4, 1e1]\n",
    "# att_cfgs['class_of_interest'] = 3\n",
    "\n",
    "# cfgs['attack'] = att_cfgs\n",
    "\n",
    "''' trun off the beta update scheduler '''\n",
    "att_cfgs = {}\n",
    "att_cfgs['num_iter'] = 8\n",
    "att_cfgs['lr'] = 2e-4\n",
    "att_cfgs['output_dir'] = './save_dir'\n",
    "att_cfgs['epsilon'] = 0.03\n",
    "att_cfgs['start_beta'] = None\n",
    "att_cfgs['end_beta'] = None\n",
    "att_cfgs['beta_growth'] = False\n",
    "att_cfgs['prefactors'] = [8e4, 1e1]\n",
    "cfgs['attack'] = att_cfgs\n",
    "\n",
    "label_dict = {'0': [1., 0., 0., 0., 0.],\n",
    "              '1': [0., 1., 0., 0., 0.],\n",
    "              '2': [0., 0., 1., 0., 0.],\n",
    "              '3': [0., 0., 0., 1., 0.],\n",
    "              '4': [0., 0., 0., 0., 1.]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46101c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for imgs, labels, idx in valid_dataloader:\n",
    "#     print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7af124",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for ii in np.arange(5):\n",
    "    \n",
    "    org_imgs = []\n",
    "    adv_imgs = []\n",
    "    org_labels = []\n",
    "    source_org_hm = [[] for _ in range(len(cfgs['model']['src_models']))]\n",
    "    source_org_pred = [[] for _ in range(len(cfgs['model']['src_models']))]\n",
    "    # target_org_hm = [[] for _ in range(len(cfgs['model']['tgt_models']))]\n",
    "    # target_org_pred = [[] for _ in range(len(cfgs['model']['tgt_models']))]\n",
    "    source_adv_hm = [[] for _ in range(len(cfgs['model']['src_models']))]\n",
    "    source_adv_pred = [[] for _ in range(len(cfgs['model']['src_models']))]\n",
    "    # target_adv_hm = [[] for _ in range(len(cfgs['model']['tgt_models']))]\n",
    "    # target_adv_pred = [[] for _ in range(len(cfgs['model']['tgt_models']))]\n",
    "    # class_of_interest = [1., 0., 0., 0., 0.]\n",
    "    iteration = 0\n",
    "\n",
    "\n",
    "    for imgs, labels, idx in valid_dataloader:\n",
    "        print('===========Iteration %d===========' % iteration)\n",
    "\n",
    "        iteration += 1\n",
    "#         try: first_one_position = np.where(np.array(labels[0]) == 1)[0][0] ## first 1\n",
    "#         except: first_one_position = -1  ### no 1\n",
    "        class_of_interest = label_dict[str(ii)]\n",
    "\n",
    "#         if labels[0][ii] == 1:\n",
    "#             class_of_interest = label_dict[str(ii)]\n",
    "#             print('interest: {}, labels: {}'.format(ii, labels))\n",
    "#         else:\n",
    "#             continue\n",
    "\n",
    "    #     if iteration > 10:\n",
    "    #         break\n",
    "        try: del source_exp_models, target_exp_models\n",
    "        except: pass\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        org_images = imgs.detach()\n",
    "        org_labels.append(labels)\n",
    "        source_exp_models = [expmodel_factory(model_cfgs, cfgs) for model_cfgs in cfgs['model']['src_models']]\n",
    "    #     target_exp_models = [expmodel_factory(model_cfgs, cfgs) for model_cfgs in cfgs['model']['tgt_models']]\n",
    "    \n",
    "        _advs = attack_pred_T_old(\n",
    "                                source_exp_models,\n",
    "                                imgs.detach(),\n",
    "                                class_of_interest,\n",
    "                                labels.detach(),\n",
    "                                cfgs,\n",
    "                            )\n",
    "        \n",
    "        adv_imgs.append(_advs.data.cpu())\n",
    "        org_imgs.append(org_images.data.cpu())\n",
    "\n",
    "        source_exp_models = [expmodel_factory(model_cfgs, cfgs) for model_cfgs in cfgs['model']['src_models']]\n",
    "\n",
    "        _advs = _advs.detach()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        s_org = [_.cal_exp_map(org_images.cuda(), class_of_interest) for _ in source_exp_models]\n",
    "        \n",
    "        for i in range(len(s_org)):\n",
    "            source_org_hm[i].append(s_org[i][0].data.cpu())\n",
    "            source_org_pred[i].append(s_org[i][1].data.cpu())\n",
    "\n",
    "        del s_org\n",
    "\n",
    "        s_adv = [_.cal_exp_map(_advs.detach().cuda(), class_of_interest) for _ in source_exp_models]\n",
    "\n",
    "        for i in range(len(s_adv)):\n",
    "            source_adv_hm[i].append(s_adv[i][0].data.cpu())\n",
    "            source_adv_pred[i].append(s_adv[i][1].data.cpu())\n",
    "\n",
    "        del s_adv, _advs, source_exp_models\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    '''save npy images'''\n",
    "    adv_imgs = torch.cat(adv_imgs, dim=0)\n",
    "    print(adv_imgs.shape)\n",
    "    org_imgs = torch.cat(org_imgs, dim=0)\n",
    "    print(org_imgs.shape)\n",
    "\n",
    "    source_org_hm = torch.cat(source_org_hm[0], dim=0).unsqueeze_(1)\n",
    "    print(source_org_hm.shape)\n",
    "    source_org_pred = torch.cat(source_org_pred[0], dim=0)\n",
    "    print(source_org_pred.shape)\n",
    "\n",
    "    source_adv_hm = torch.cat(source_adv_hm[0], dim=0).unsqueeze_(1)\n",
    "    print(source_adv_hm.shape)\n",
    "    source_adv_pred = torch.cat(source_adv_pred[0], dim=0)\n",
    "    print(source_adv_pred.shape)\n",
    "\n",
    "    # source_org_hm = [torch.cat(_, dim=0) for _ in source_org_hm]\n",
    "    # source_org_pred = [torch.cat(_, dim=0) for _ in source_org_pred]\n",
    "    # target_org_hm = [torch.cat(_, dim=0) for _ in target_org_hm]\n",
    "    # target_org_pred = [torch.cat(_, dim=0) for _ in target_org_pred]\n",
    "    # source_adv_hm = [torch.cat(_, dim=0) for _ in source_adv_hm]\n",
    "    # source_adv_pred = [torch.cat(_, dim=0) for _ in source_adv_pred]\n",
    "    # target_adv_hm = [torch.cat(_, dim=0) for _ in target_adv_hm]\n",
    "    # target_adv_pred = [torch.cat(_, dim=0) for _ in target_adv_pred]\n",
    "\n",
    "    org_labels = torch.cat(org_labels, dim=0)\n",
    "    print('original label size: ', org_labels.size())\n",
    "\n",
    "    '''save image cubes'''\n",
    "    cfgs['output_dir'] = '/data/users/Attack_Attn/save_dir/NatComm/attack_pred'\n",
    "    save_dir = os.path.join(cfgs['output_dir'], \n",
    "                            model_cfgs['src_models'][0]['model_info']['model_name']+'_'+\\\n",
    "                            model_cfgs['src_models'][0]['exp_method']+\\\n",
    "                            '_class_'+str(ii))\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    np.save(os.path.join(save_dir, 'org_imgs.npy'), org_imgs.numpy())\n",
    "    np.save(os.path.join(save_dir, 'adv_imgs.npy'), adv_imgs.numpy())\n",
    "\n",
    "    np.save(os.path.join(save_dir, 'org_hm.npy'), source_org_hm.numpy())\n",
    "    np.save(os.path.join(save_dir, 'adv_hm.npy'), source_adv_hm.numpy())\n",
    "\n",
    "    np.save(os.path.join(save_dir, 'org_labels.npy'), org_labels.numpy())\n",
    "    np.save(os.path.join(save_dir, 'org_pred.npy'), source_org_pred.numpy())\n",
    "    np.save(os.path.join(save_dir, 'adv_pred.npy'), source_adv_pred.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21044d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# org_labels = []\n",
    "# for imgs, labels, idx in valid_dataloader:\n",
    "#     org_labels.append(labels)\n",
    "# org_labels = torch.cat(org_labels, dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c86397",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addd5176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(outputs, targets):\n",
    "    n_classes = outputs.shape[1]\n",
    "    fpr, tpr, aucs, precision, recall = {}, {}, {}, {}, {}\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(targets[:,i], outputs[:,i])\n",
    "        aucs[i] = auc(fpr[i], tpr[i])\n",
    "        precision[i], recall[i], _ = precision_recall_curve(targets[:,i], outputs[:,i])\n",
    "        fpr[i], tpr[i], precision[i], recall[i] = fpr[i].tolist(), tpr[i].tolist(), precision[i].tolist(), recall[i].tolist()\n",
    "\n",
    "    metrics = {'fpr': fpr,\n",
    "               'tpr': tpr,\n",
    "               'aucs': aucs,\n",
    "               'precision': precision,\n",
    "               'recall': recall}\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a9cf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_img_similarity(imgs_1, imgs_2):\n",
    "    assert len(imgs_1.shape) == len(imgs_2.shape) == 3\n",
    "    ssim_vals = []\n",
    "    pcc_vals = []\n",
    "    imgs_1 = batch_img_norm(imgs_1) * 255\n",
    "    imgs_2 = batch_img_norm(imgs_2) * 255\n",
    "    for i in range(imgs_1.shape[0]):\n",
    "        _img1 = imgs_1[i]\n",
    "        _img2 = imgs_2[i]\n",
    "        if np.isnan(_img1.mean()) or np.isnan(_img2.mean()):\n",
    "            print(i)\n",
    "            continue\n",
    "        \n",
    "        # SSIM\n",
    "        _ssim, _ = ssim(_img1, _img2, data_range=255, full=True, multichannel=False)\n",
    "        ssim_vals.append(_ssim)\n",
    "        \n",
    "        # PCC\n",
    "        _pcc = pearsonr(_img1.reshape(-1), _img2.reshape(-1))[0]\n",
    "        pcc_vals.append(_pcc)\n",
    "    \n",
    "    # MSE\n",
    "    mse_vals = np.nanmean(((imgs_1/255 - imgs_2/255)**2).mean(-1))\n",
    "    return {\n",
    "        'ssim': np.asarray(ssim_vals),\n",
    "        'mse': mse_vals,\n",
    "        'pcc': np.asarray(pcc_vals),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d05ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfgs['output_dir'] = '/data/users/Attack_Attn/save_dir/NatComm/attack_pred'\n",
    "#     save_dir = os.path.join(cfgs['output_dir'], \n",
    "#                             model_cfgs['src_models'][0]['model_info']['model_name']+'_'+\\\n",
    "#                             model_cfgs['src_models'][0]['exp_method']+\\\n",
    "#                             '_class_'+str(ii))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a436fd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def eval_auc_sim(model_name, xai_name):\n",
    "def load_all(model_name, xai_name, ii_specific=None):\n",
    "#     model_name = model_cfgs['src_models'][0]['model_info']['model_name']\n",
    "#     xai_name = model_cfgs['src_models'][0]['exp_method']\n",
    "    img_org, img_att = [], []\n",
    "    pred_org, pred_att, label = [], [], []\n",
    "    hm_org, hm_att = [], []\n",
    "    \n",
    "    if ii_specific is None:\n",
    "        for ii in np.arange(5):\n",
    "            save_dir = os.path.join(cfgs['output_dir'], \n",
    "                                    model_cfgs['src_models'][0]['model_info']['model_name']+'_'+\\\n",
    "                                    xai_name+\\\n",
    "                                    '_class_'+str(ii))\n",
    "            '''load predictions'''\n",
    "            pred_org.append(np.load(os.path.join(save_dir, 'org_pred.npy')))\n",
    "            pred_att.append(np.load(os.path.join(save_dir, 'adv_pred.npy')))\n",
    "            label.append(np.load(os.path.join(save_dir, 'org_labels.npy')))\n",
    "            '''load heat map'''\n",
    "            hm_org.append(np.load(os.path.join(save_dir, 'org_hm.npy')))\n",
    "            hm_att.append(np.load(os.path.join(save_dir, 'adv_hm.npy')))\n",
    "            '''load images'''\n",
    "            img_org.append(np.load(os.path.join(save_dir, 'org_imgs.npy')))\n",
    "            img_att.append(np.load(os.path.join(save_dir, 'adv_imgs.npy')))\n",
    "\n",
    "        pred_org = np.concatenate(pred_org, 0)\n",
    "        pred_att = np.concatenate(pred_att, 0)\n",
    "        label = np.concatenate(label, 0)\n",
    "\n",
    "        hm_org = np.concatenate(hm_org, 0)\n",
    "        hm_att = np.concatenate(hm_att, 0)\n",
    "\n",
    "        img_org = np.concatenate(img_org, 0)\n",
    "        img_att = np.concatenate(img_att, 0)\n",
    "    else:\n",
    "        save_dir = os.path.join(cfgs['output_dir'], \n",
    "                                    model_cfgs['src_models'][0]['model_info']['model_name']+'_'+\\\n",
    "                                    xai_name+\\\n",
    "                                    '_class_'+str(ii_specific))\n",
    "        '''load predictions'''\n",
    "        pred_org = np.load(os.path.join(save_dir, 'org_pred.npy'))\n",
    "        pred_att = np.load(os.path.join(save_dir, 'adv_pred.npy'))\n",
    "        label = np.load(os.path.join(save_dir, 'org_labels.npy'))\n",
    "        '''load heat map'''\n",
    "        hm_org = np.load(os.path.join(save_dir, 'org_hm.npy'))\n",
    "        hm_att = np.load(os.path.join(save_dir, 'adv_hm.npy'))\n",
    "        '''load images'''\n",
    "        img_org = np.load(os.path.join(save_dir, 'org_imgs.npy'))\n",
    "        img_att = np.load(os.path.join(save_dir, 'adv_imgs.npy')) \n",
    "    \n",
    "    return [img_org, img_att], [hm_org, hm_att], [pred_org, pred_att, label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fcbfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_all_metrics(model_name, xai_name, ii_specific=None):\n",
    "    img_, hm_, pred_ = load_all(model_name, xai_name, ii_specific)\n",
    "    \n",
    "    if ii_specific is None:\n",
    "        print('+++++++++++++++++++++ all images ++++++++++++++++++++')\n",
    "    else:\n",
    "        print('+++++++++++++++++++++ class {} ++++++++++++++++++++'.format(ii_specific))\n",
    "        \n",
    "    print('=== Org AUC ===')\n",
    "    auc_org = compute_metrics(pred_[0], pred_[2])['aucs']\n",
    "    print(auc_org)\n",
    "    \n",
    "    print('=== Attack AUC ===')\n",
    "    auc_att = compute_metrics(pred_[1], pred_[2])['aucs']\n",
    "    print(auc_att)\n",
    "    \n",
    "    print('=== Heat Map ===')\n",
    "    res = eval_img_similarity(hm_[0][:,0,:,:], hm_[1][:,0,:,:])\n",
    "    for _k in res.keys():\n",
    "        _v = np.nanmean(res[_k])\n",
    "        print(_k, _v)\n",
    "        if _k == 'ssim': ssim_hp = _v\n",
    "        if _k == 'mse': mse_hp = _v\n",
    "    \n",
    "    print('=== Image ===')\n",
    "    res = eval_img_similarity(img_[0][:,0,:,:], img_[1][:,0,:,:])\n",
    "    for _k in res.keys():\n",
    "        _v = np.nanmean(res[_k])\n",
    "        print(_k, _v)\n",
    "        if _k == 'ssim': ssim_im = _v\n",
    "        if _k == 'mse': mse_im = _v\n",
    "            \n",
    "    return auc_org[ii_specific], auc_att[ii_specific], ssim_hp, mse_hp, ssim_im, mse_im"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84275c0e",
   "metadata": {},
   "source": [
    "### load and eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ed755e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# xai_names = ['VanillaBP']\n",
    "num_classes = len(valid_dataloader.dataset.attr_names)\n",
    "xai_names = ['VanillaBP', 'VanillaBP_Img', 'IntegratedBP', 'GradCAM', 'SmoothBP']\n",
    "model_name_list = ['resnet152', 'densenet121']\n",
    "\n",
    "for model_name in model_name_list:\n",
    "    print('-------------------------------- {} --------------------------------'.format(model_name))\n",
    "    for xai_name in xai_names:\n",
    "        print('-------------------------------- {} --------------------------------'.format(xai_name))\n",
    "        AUC_org, AUC_att, SSIM_hp, MSE_hp, SSIM_im, MSE_im = 0,0,0,0,0,0\n",
    "        for ii in np.arange(num_classes):\n",
    "            auc_org, auc_att, ssim_hp, mse_hp, ssim_im, mse_im = eval_all_metrics(model_name, xai_name, ii)\n",
    "            AUC_org += auc_org/num_classes\n",
    "            AUC_att += auc_att/num_classes\n",
    "            SSIM_hp += ssim_hp/num_classes\n",
    "            SSIM_im += ssim_im/num_classes\n",
    "            MSE_hp  += mse_hp/num_classes\n",
    "            MSE_im  += mse_im/num_classes\n",
    "    #     eval_all_metrics(model_name, xai_name, None)\n",
    "        print('============= averaged results of {} ============= '.format(xai_name))\n",
    "        print('AUC_org: ',AUC_org)\n",
    "        print('AUC_att: ',AUC_att)\n",
    "        print('SSIM_hp: ',SSIM_hp)\n",
    "        print('SSIM_im: ',SSIM_im)\n",
    "        print('MSE_hp: ',MSE_hp)\n",
    "        print('MSE_im: ',MSE_im)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98eb982b",
   "metadata": {},
   "source": [
    "### Compute and save heatmap of G-GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f36843",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {'0': [1., 0., 0., 0., 0.],\n",
    "              '1': [0., 1., 0., 0., 0.],\n",
    "              '2': [0., 0., 1., 0., 0.],\n",
    "              '3': [0., 0., 0., 1., 0.],\n",
    "              '4': [0., 0., 0., 0., 1.]}\n",
    "\n",
    "'''init model'''\n",
    "dense121_cfgs = {\n",
    "    'model_info':{\n",
    "        'model_name': 'densenet121',\n",
    "        'model_path': '/home/Attack_Attn/ChestXpert/save_dir_multimodel/densenet121_5c/best_checkpoints/checkpoint_9.pt',\n",
    "#         'model_path': '/home/Attack_Attn/ChestXpert/save_dir_multimodel/densenet121_weakrobust/best_checkpoints/checkpoint_9.pt',\n",
    "#         'model_path': '/home/Attack_Attn/ChestXpert/save_dir_multimodel/robust_densenet121/best_checkpoints/checkpoint_9.pt',\n",
    "    },\n",
    "    'exp_method': 'GuidedGradCAM',\n",
    "    'exp_cfgs':{\n",
    "        'target_layer': ['features','denseblock4','denselayer14'],\n",
    "    }\n",
    "}\n",
    "\n",
    "model_cfgs = {}\n",
    "model_cfgs['src_models']=[\n",
    "    dense121_cfgs,\n",
    "#     mobilV2_cfgs,\n",
    "#     res152_cfgs,\n",
    "]\n",
    "model_cfgs['tgt_models']=[\n",
    "#     res152_cfgs,\n",
    "]\n",
    "model_cfgs['pretrained'] = False\n",
    "cfgs['model'] = model_cfgs\n",
    "source_exp_models = [expmodel_factory(model_cfgs, cfgs) for model_cfgs in cfgs['model']['src_models']]\n",
    "\n",
    "\n",
    "'''load data from GradCAM'''\n",
    "xai_names =  ['VanillaBP', 'VanillaBP_Img', 'GuidedBP', 'IntegratedBP', 'GradCAM', 'GuidedGradCAM', 'SmoothBP', 'XRAI']\n",
    "model_name = 'densenet121'\n",
    "img_, hm_, pred_ = load_all(model_name='densenet121', xai_name='GradCAM', ii_specific=1)\n",
    "print(img_[0].shape) # original image\n",
    "print(img_[1].shape) # adversarial image\n",
    "# image_num, _, _, _ = img_[0].shape\n",
    "# print(image_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607b34a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for ii in np.arange(5): # 5 different classes\n",
    "    print('==================== calss number: {} ===================='.format(ii))\n",
    "    hm_org, hm_att = [], []\n",
    "    img_, hm_, pred_ = load_all(model_name='densenet121', xai_name='GradCAM', ii_specific=ii)\n",
    "    image_num, _, _, _ = img_[0].shape\n",
    "    save_dir = os.path.join(cfgs['output_dir'], \n",
    "                            model_cfgs['src_models'][0]['model_info']['model_name']+'_'+\\\n",
    "                            model_cfgs['src_models'][0]['exp_method']+\\\n",
    "                            '_class_'+str(ii))\n",
    "    class_of_interest = label_dict[str(ii)]\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    for img_index in np.arange(image_num):\n",
    "        print('---- img_index: {} ----'.format(img_index))\n",
    "        img_org = torch.Tensor(img_[0][img_index]).clone().detach()\n",
    "        img_adv = torch.Tensor(img_[1][img_index]).clone().detach()\n",
    "#         class_of_interest = torch.Tensor(pred_[2][0])\n",
    "#         print(img_org.size())\n",
    "        res_org = [_.cal_exp_map(img_org.to(torch.device(cfgs['device'])).unsqueeze(0), class_of_interest) for _ in source_exp_models]\n",
    "        res_adv = [_.cal_exp_map(img_adv.to(torch.device(cfgs['device'])).unsqueeze(0), class_of_interest) for _ in source_exp_models]\n",
    "\n",
    "        hm_org.append(res_org[0][0].data.cpu())\n",
    "        hm_att.append(res_adv[0][0].data.cpu())\n",
    "        del res_org, res_adv\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    '''save npy images'''\n",
    "    hm_org = torch.cat(hm_org, dim=0).unsqueeze_(1)\n",
    "    hm_att = torch.cat(hm_att, dim=0).unsqueeze_(1)\n",
    "    print(hm_org.shape)\n",
    "    \n",
    "    np.save(os.path.join(save_dir, 'hm_org.npy'), hm_org.numpy())\n",
    "    np.save(os.path.join(save_dir, 'hm_att.npy'), hm_att.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8459aeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a81e763",
   "metadata": {},
   "source": [
    "### Compute and save heatmap of XRAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65364a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {'0': [1., 0., 0., 0., 0.],\n",
    "              '1': [0., 1., 0., 0., 0.],\n",
    "              '2': [0., 0., 1., 0., 0.],\n",
    "              '3': [0., 0., 0., 1., 0.],\n",
    "              '4': [0., 0., 0., 0., 1.]}\n",
    "\n",
    "'''init model'''\n",
    "dense121_cfgs = {\n",
    "    'model_info':{\n",
    "        'model_name': 'densenet121',\n",
    "        'model_path': '/home/Attack_Attn/ChestXpert/save_dir_multimodel/densenet121_5c/best_checkpoints/checkpoint_9.pt',\n",
    "#         'model_path': '/home/Attack_Attn/ChestXpert/save_dir_multimodel/densenet121_weakrobust/best_checkpoints/checkpoint_9.pt',\n",
    "#         'model_path': '/home/Attack_Attn/ChestXpert/save_dir_multimodel/robust_densenet121/best_checkpoints/checkpoint_9.pt',\n",
    "    },\n",
    "    'exp_method': 'XRAI',\n",
    "    'exp_cfgs':{\n",
    "#         'target_layer': ['features','denseblock4','denselayer14'],\n",
    "    }\n",
    "}\n",
    "\n",
    "model_cfgs = {}\n",
    "model_cfgs['src_models']=[\n",
    "    dense121_cfgs,\n",
    "#     mobilV2_cfgs,\n",
    "#     res152_cfgs,\n",
    "]\n",
    "model_cfgs['tgt_models']=[\n",
    "#     res152_cfgs,\n",
    "]\n",
    "model_cfgs['pretrained'] = False\n",
    "cfgs['model'] = model_cfgs\n",
    "source_exp_models = [expmodel_factory(model_cfgs, cfgs) for model_cfgs in cfgs['model']['src_models']]\n",
    "\n",
    "\n",
    "'''load data from GradCAM'''\n",
    "xai_names =  ['VanillaBP', 'VanillaBP_Img', 'GuidedBP', 'IntegratedBP', 'GradCAM', 'GuidedGradCAM', 'SmoothBP', 'XRAI']\n",
    "model_name = 'densenet121'\n",
    "img_, hm_, pred_ = load_all(model_name='densenet121', xai_name='IntegratedBP', ii_specific=1)\n",
    "print(img_[0].shape) # original image\n",
    "print(img_[1].shape) # adversarial image\n",
    "# image_num, _, _, _ = img_[0].shape\n",
    "# print(image_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b19d402",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for ii in np.arange(5): # 5 different classes\n",
    "    print('==================== calss number: {} ===================='.format(ii))\n",
    "    hm_org, hm_att = [], []\n",
    "    img_, hm_, pred_ = load_all(model_name='densenet121', xai_name='IntegratedBP', ii_specific=ii)\n",
    "    image_num, _, _, _ = img_[0].shape\n",
    "    save_dir = os.path.join(cfgs['output_dir'], \n",
    "                            model_cfgs['src_models'][0]['model_info']['model_name']+'_'+\\\n",
    "                            model_cfgs['src_models'][0]['exp_method']+\\\n",
    "                            '_class_'+str(ii))\n",
    "    class_of_interest = label_dict[str(ii)]\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    for img_index in np.arange(image_num):\n",
    "        print('---- img_index: {} ----'.format(img_index))\n",
    "        img_org = torch.Tensor(img_[0][img_index]).clone().detach()\n",
    "        img_adv = torch.Tensor(img_[1][img_index]).clone().detach()\n",
    "#         class_of_interest = torch.Tensor(pred_[2][0])\n",
    "#         print(img_org.size())\n",
    "        res_org = [_.cal_exp_map(img_org.to(torch.device(cfgs['device'])).unsqueeze(0), class_of_interest) for _ in source_exp_models]\n",
    "        res_adv = [_.cal_exp_map(img_adv.to(torch.device(cfgs['device'])).unsqueeze(0), class_of_interest) for _ in source_exp_models]\n",
    "\n",
    "        hm_org.append(torch.Tensor(res_org[0][0]).unsqueeze_(0))\n",
    "        hm_att.append(torch.Tensor(res_adv[0][0]).unsqueeze_(0))\n",
    "        del res_org, res_adv\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    '''save npy images'''\n",
    "    hm_org = torch.cat(hm_org, dim=0).unsqueeze_(1)\n",
    "    hm_att = torch.cat(hm_att, dim=0).unsqueeze_(1)\n",
    "    print(hm_org.shape)\n",
    "    \n",
    "    np.save(os.path.join(save_dir, 'hm_org.npy'), hm_org.numpy())\n",
    "    np.save(os.path.join(save_dir, 'hm_att.npy'), hm_att.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f91b950",
   "metadata": {},
   "source": [
    "### eval G-GradCAM and XRAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974af538",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all__(model_name, xai_name, ii_specific=None):\n",
    "#     model_name = model_cfgs['src_models'][0]['model_info']['model_name']\n",
    "#     xai_name = model_cfgs['src_models'][0]['exp_method']\n",
    "    hm_org, hm_att = [], []\n",
    "    \n",
    "    if ii_specific is None:\n",
    "        for ii in np.arange(5):\n",
    "            save_dir = os.path.join(cfgs['output_dir'], \n",
    "                                    model_cfgs['src_models'][0]['model_info']['model_name']+'_'+\\\n",
    "                                    xai_name+\\\n",
    "                                    '_class_'+str(ii))\n",
    "            '''load heat map'''\n",
    "            hm_org.append(np.load(os.path.join(save_dir, 'hm_org.npy')))\n",
    "            hm_att.append(np.load(os.path.join(save_dir, 'hm_att.npy')))\n",
    "\n",
    "        hm_org = np.concatenate(hm_org, 0)\n",
    "        hm_att = np.concatenate(hm_att, 0)\n",
    "    else:\n",
    "        save_dir = os.path.join(cfgs['output_dir'], \n",
    "                                    model_cfgs['src_models'][0]['model_info']['model_name']+'_'+\\\n",
    "                                    xai_name+\\\n",
    "                                    '_class_'+str(ii_specific))\n",
    "        '''load heat map'''\n",
    "        hm_org = np.load(os.path.join(save_dir, 'hm_org.npy'))\n",
    "        hm_att = np.load(os.path.join(save_dir, 'hm_att.npy'))\n",
    "    \n",
    "    return [hm_org, hm_att]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c974c1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_all_metrics__(model_name, xai_name, ii_specific=None):\n",
    "    hm_ = load_all__(model_name, xai_name, ii_specific)\n",
    "    if ii_specific is None:\n",
    "        print('+++++++++++++++++++++ all images ++++++++++++++++++++')\n",
    "    else:\n",
    "        print('+++++++++++++++++++++ class {} ++++++++++++++++++++'.format(ii_specific))\n",
    "    \n",
    "    print('=== Heat Map ===')\n",
    "    res = eval_img_similarity(hm_[0][:,0,:,:], hm_[1][:,0,:,:])\n",
    "    for _k in res.keys():\n",
    "        print(_k, np.nanmean(res[_k]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297b4e64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xai_names =  ['GuidedGradCAM', 'XRAI']\n",
    "model_name = 'densenet121'\n",
    "for xai_name in xai_names:\n",
    "    print('-------------------------------- {} --------------------------------'.format(xai_name))\n",
    "    for ii in np.arange(5):\n",
    "        eval_all_metrics__(model_name, xai_name, ii)\n",
    "    eval_all_metrics__(model_name, xai_name, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee2a600",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_org[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5579ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for heatmap, pred in res:\n",
    "#     print(torch.sigmoid(pred))\n",
    "#     heatmap = heatmap.data.cpu().numpy()\n",
    "#     heatmap = img_norm(heatmap) # norm grad to speial range\n",
    "#     cmap = cm.jet_r(1-heatmap)[..., :3]     # color map proj\n",
    "#     cmap = img_norm(cmap)                     # re-norm to [0,1]\n",
    "    \n",
    "#     ## load original image\n",
    "#     base_img = _img[0].data.cpu().expand(3,-1,-1).permute(1,2,0)\n",
    "#     alpha = .99\n",
    "#     htmp_weight = np.zeros_like(cmap.squeeze())\n",
    "#     print(htmp_weight.shape)\n",
    "#     htmp_weight[:,:,0], htmp_weight[:,:,1], htmp_weight[:,:,2] = heatmap, heatmap, heatmap\n",
    "#     img_fused = base_img*(1-htmp_weight) + cmap*alpha*htmp_weight\n",
    "    \n",
    "    \n",
    "#     plt.figure(figsize=(6,6))\n",
    "#     base_img = _img[0].data.cpu().expand(3,-1,-1).permute(1,2,0)\n",
    "#     alpha = .5\n",
    "#     img_fused = base_img*(1-alpha) + cmap*alpha\n",
    "#     plt.subplot(2,2,1)\n",
    "#     plt.imshow(_img[0], cmap='gray')\n",
    "#     plt.subplot(2,2,2)\n",
    "# #     plt.imshow(attack_target_maps[0].data.cpu(), cmap='gray')\n",
    "#     plt.subplot(2,2,3)\n",
    "#     plt.imshow(_img[0].data.cpu().numpy(), cmap='gray')\n",
    "#     plt.subplot(2,2,4)\n",
    "#     plt.imshow(img_fused[0])\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccaa8f5",
   "metadata": {},
   "source": [
    "## attack EXPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4129fb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' trun on the beta update scheduler '''\n",
    "att_cfgs['start_beta'] = 10 #None\n",
    "att_cfgs['end_beta'] = 100 #None\n",
    "att_cfgs['beta_growth'] = True #False\n",
    "att_cfgs['num_iter'] = 200\n",
    "att_cfgs['lr'] = 2e-4\n",
    "att_cfgs['epsilon'] = 0.06\n",
    "att_cfgs['prefactors'] = [1e14, 1e4]\n",
    "cfgs['attack'] = att_cfgs\n",
    "\n",
    "label_dict = {'0': [1., 0., 0., 0., 0.],\n",
    "              '1': [0., 1., 0., 0., 0.],\n",
    "              '2': [0., 0., 1., 0., 0.],\n",
    "              '3': [0., 0., 0., 1., 0.],\n",
    "              '4': [0., 0., 0., 0., 1.]}\n",
    "\n",
    "attack_target_maps = torch.zeros_like(img).detach_()\n",
    "attack_target_maps[:, 130:190, 380:440] = 1.0/3600 # binary mask\n",
    "attack_target_maps = attack_target_maps.to(torch.device(cfgs['device'])).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f832666f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for ii in np.arange(5):\n",
    "    \n",
    "    org_imgs = []\n",
    "    adv_imgs = []\n",
    "    org_labels = []\n",
    "    source_org_hm = [[] for _ in range(len(cfgs['model']['src_models']))]\n",
    "    source_org_pred = [[] for _ in range(len(cfgs['model']['src_models']))]\n",
    "    # target_org_hm = [[] for _ in range(len(cfgs['model']['tgt_models']))]\n",
    "    # target_org_pred = [[] for _ in range(len(cfgs['model']['tgt_models']))]\n",
    "    source_adv_hm = [[] for _ in range(len(cfgs['model']['src_models']))]\n",
    "    source_adv_pred = [[] for _ in range(len(cfgs['model']['src_models']))]\n",
    "    # target_adv_hm = [[] for _ in range(len(cfgs['model']['tgt_models']))]\n",
    "    # target_adv_pred = [[] for _ in range(len(cfgs['model']['tgt_models']))]\n",
    "    # class_of_interest = [1., 0., 0., 0., 0.]\n",
    "    iteration = 0\n",
    "    print('---------------------- Class %d ---------------------' % ii)\n",
    "    for imgs, labels, idx in valid_dataloader:\n",
    "        print('====== Iteration %d ======' % iteration)\n",
    "\n",
    "        iteration += 1\n",
    "#         if iteration >10:\n",
    "#             break\n",
    "#         try: first_one_position = np.where(np.array(labels[0]) == 1)[0][0] ## first 1\n",
    "#         except: first_one_position = -1  ### no 1\n",
    "        class_of_interest = label_dict[str(ii)]\n",
    "    \n",
    "        try: del source_exp_models\n",
    "        except: pass\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        org_images = imgs.detach()\n",
    "        org_labels.append(labels)\n",
    "        source_exp_models = [expmodel_factory(model_cfgs, cfgs) for model_cfgs in cfgs['model']['src_models']]\n",
    "        '''get adversarial images'''\n",
    "        if labels[0][ii] == 1:\n",
    "            print('Have such class:{}, labels:{}'.format(ii, labels))\n",
    "            _advs = org_images\n",
    "            flag = 0\n",
    "        else:\n",
    "            print('No such class:{}, labels:{}, target:{}'.format(ii, labels, class_of_interest))\n",
    "            _advs = attack_expl_T(\n",
    "                                    source_exp_models, \n",
    "                                    imgs.to(torch.device(cfgs['device'])), \n",
    "                                    class_of_interest, \n",
    "                                    attack_target_maps,\n",
    "                                    cfgs, \n",
    "                                    attack_steps=200,\n",
    "                                    epsilon=0.06,\n",
    "                                    vis_iter=49\n",
    "                                )\n",
    "            flag = 1\n",
    "        '''eval'''\n",
    "        try: del source_exp_models\n",
    "        except: pass\n",
    "        adv_imgs.append(_advs.data.cpu())\n",
    "        org_imgs.append(org_images.data.cpu())\n",
    "        source_exp_models = [expmodel_factory(model_cfgs, cfgs) for model_cfgs in cfgs['model']['src_models']]\n",
    "\n",
    "        _advs = _advs.detach()\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        ### original\n",
    "        s_org = [_.cal_exp_map(org_images.cuda(), class_of_interest) for _ in source_exp_models]\n",
    "        for i in range(len(s_org)):\n",
    "            source_org_hm[i].append(s_org[i][0].data.cpu())\n",
    "            source_org_pred[i].append(s_org[i][1].data.cpu())\n",
    "\n",
    "        ### adv\n",
    "        if flag == 0:\n",
    "            source_adv_hm[i].append(s_org[i][0].data.cpu())\n",
    "            source_adv_pred[i].append(s_org[i][1].data.cpu())\n",
    "            del s_org, source_exp_models\n",
    "        else:\n",
    "            del s_org\n",
    "            s_adv = [_.cal_exp_map(_advs.detach().cuda(), class_of_interest) for _ in source_exp_models]\n",
    "            for i in range(len(s_adv)):\n",
    "                source_adv_hm[i].append(s_adv[i][0].data.cpu())\n",
    "                source_adv_pred[i].append(s_adv[i][1].data.cpu())\n",
    "            del s_adv, _advs, source_exp_models\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    '''save npy images'''\n",
    "    adv_imgs = torch.cat(adv_imgs, dim=0)\n",
    "    print(adv_imgs.shape)\n",
    "    org_imgs = torch.cat(org_imgs, dim=0)\n",
    "    print(org_imgs.shape)\n",
    "\n",
    "    source_org_hm = torch.cat(source_org_hm[0], dim=0).unsqueeze_(1)\n",
    "    print(source_org_hm.shape)\n",
    "    source_org_pred = torch.cat(source_org_pred[0], dim=0)\n",
    "    print(source_org_pred.shape)\n",
    "\n",
    "    source_adv_hm = torch.cat(source_adv_hm[0], dim=0).unsqueeze_(1)\n",
    "    print(source_adv_hm.shape)\n",
    "    source_adv_pred = torch.cat(source_adv_pred[0], dim=0)\n",
    "    print(source_adv_pred.shape)\n",
    "\n",
    "    # source_org_hm = [torch.cat(_, dim=0) for _ in source_org_hm]\n",
    "    # source_org_pred = [torch.cat(_, dim=0) for _ in source_org_pred]\n",
    "    # target_org_hm = [torch.cat(_, dim=0) for _ in target_org_hm]\n",
    "    # target_org_pred = [torch.cat(_, dim=0) for _ in target_org_pred]\n",
    "    # source_adv_hm = [torch.cat(_, dim=0) for _ in source_adv_hm]\n",
    "    # source_adv_pred = [torch.cat(_, dim=0) for _ in source_adv_pred]\n",
    "    # target_adv_hm = [torch.cat(_, dim=0) for _ in target_adv_hm]\n",
    "    # target_adv_pred = [torch.cat(_, dim=0) for _ in target_adv_pred]\n",
    "\n",
    "    org_labels = torch.cat(org_labels, dim=0)\n",
    "    print('original label size: ', org_labels.size())\n",
    "\n",
    "    '''save image cubes'''\n",
    "    cfgs['output_dir'] = '/data/users/Attack_Attn/save_dir/NatComm/attack_expl_inv'\n",
    "    save_dir = os.path.join(cfgs['output_dir'], \n",
    "                            model_cfgs['src_models'][0]['model_info']['model_name']+'_'+\\\n",
    "                            model_cfgs['src_models'][0]['exp_method']+\\\n",
    "                            '_class_'+str(ii))\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    np.save(os.path.join(save_dir, 'org_imgs.npy'), org_imgs.numpy())\n",
    "    np.save(os.path.join(save_dir, 'adv_imgs.npy'), adv_imgs.numpy())\n",
    "\n",
    "    np.save(os.path.join(save_dir, 'org_hm.npy'), source_org_hm.numpy())\n",
    "    np.save(os.path.join(save_dir, 'adv_hm.npy'), source_adv_hm.numpy())\n",
    "\n",
    "    np.save(os.path.join(save_dir, 'org_labels.npy'), org_labels.numpy())\n",
    "    np.save(os.path.join(save_dir, 'org_pred.npy'), source_org_pred.numpy())\n",
    "    np.save(os.path.join(save_dir, 'adv_pred.npy'), source_adv_pred.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0995838",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd13210e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(outputs, targets):\n",
    "    n_classes = outputs.shape[1]\n",
    "    fpr, tpr, aucs, precision, recall = {}, {}, {}, {}, {}\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(targets[:,i], outputs[:,i])\n",
    "        aucs[i] = auc(fpr[i], tpr[i])\n",
    "        precision[i], recall[i], _ = precision_recall_curve(targets[:,i], outputs[:,i])\n",
    "        fpr[i], tpr[i], precision[i], recall[i] = fpr[i].tolist(), tpr[i].tolist(), precision[i].tolist(), recall[i].tolist()\n",
    "\n",
    "    metrics = {'fpr': fpr,\n",
    "               'tpr': tpr,\n",
    "               'aucs': aucs,\n",
    "               'precision': precision,\n",
    "               'recall': recall}\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d948c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_img_similarity(imgs_1, imgs_2):\n",
    "    assert len(imgs_1.shape) == len(imgs_2.shape) == 3\n",
    "    ssim_vals = []\n",
    "    pcc_vals = []\n",
    "    imgs_1 = batch_img_norm(imgs_1) * 255\n",
    "    imgs_2 = batch_img_norm(imgs_2) * 255\n",
    "    for i in range(imgs_1.shape[0]):\n",
    "        _img1 = imgs_1[i]\n",
    "        _img2 = imgs_2[i]\n",
    "        if np.isnan(_img1.mean()) or np.isnan(_img2.mean()):\n",
    "            print(i)\n",
    "            continue\n",
    "        \n",
    "        # SSIM\n",
    "        _ssim, _ = ssim(_img1, _img2, data_range=255, full=True, multichannel=False)\n",
    "        ssim_vals.append(_ssim)\n",
    "        \n",
    "        # PCC\n",
    "        _pcc = pearsonr(_img1.reshape(-1), _img2.reshape(-1))[0]\n",
    "        pcc_vals.append(_pcc)\n",
    "        \n",
    "        # JS-div\n",
    "        \n",
    "    \n",
    "    # MSE\n",
    "    mse_vals = np.nanmean(((imgs_1/255 - imgs_2/255)**2).mean(-1))\n",
    "    return {\n",
    "        'ssim': np.asarray(ssim_vals),\n",
    "        'mse': mse_vals,\n",
    "        'pcc': np.asarray(pcc_vals),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d728eda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def eval_auc_sim(model_name, xai_name):\n",
    "def load_all(model_name, xai_name, ii_specific=None):\n",
    "#     model_name = model_cfgs['src_models'][0]['model_info']['model_name']\n",
    "#     xai_name = model_cfgs['src_models'][0]['exp_method']\n",
    "    img_org, img_att = [], []\n",
    "    pred_org, pred_att, label = [], [], []\n",
    "    hm_org, hm_att = [], []\n",
    "    \n",
    "    if ii_specific is None:\n",
    "        for ii in np.arange(5):\n",
    "            save_dir = os.path.join(cfgs['output_dir'], \n",
    "                                    model_name+'_'+\\\n",
    "                                    xai_name+\\\n",
    "                                    '_class_'+str(ii))\n",
    "            '''load predictions'''\n",
    "            pred_org.append(np.load(os.path.join(save_dir, 'org_pred.npy')))\n",
    "            pred_att.append(np.load(os.path.join(save_dir, 'adv_pred.npy')))\n",
    "            label.append(np.load(os.path.join(save_dir, 'org_labels.npy')))\n",
    "            '''load heat map'''\n",
    "            hm_org.append(np.load(os.path.join(save_dir, 'org_hm.npy')))\n",
    "            hm_att.append(np.load(os.path.join(save_dir, 'adv_hm.npy')))\n",
    "            '''load images'''\n",
    "            img_org.append(np.load(os.path.join(save_dir, 'org_imgs.npy')))\n",
    "            img_att.append(np.load(os.path.join(save_dir, 'adv_imgs.npy')))\n",
    "\n",
    "        pred_org = np.concatenate(pred_org, 0)\n",
    "        pred_att = np.concatenate(pred_att, 0)\n",
    "        label = np.concatenate(label, 0)\n",
    "\n",
    "        hm_org = np.concatenate(hm_org, 0)\n",
    "        hm_att = np.concatenate(hm_att, 0)\n",
    "\n",
    "        img_org = np.concatenate(img_org, 0)\n",
    "        img_att = np.concatenate(img_att, 0)\n",
    "    else:\n",
    "        save_dir = os.path.join(cfgs['output_dir'], \n",
    "                                    model_cfgs['src_models'][0]['model_info']['model_name']+'_'+\\\n",
    "                                    xai_name+\\\n",
    "                                    '_class_'+str(ii_specific))\n",
    "        '''load predictions'''\n",
    "        pred_org = np.load(os.path.join(save_dir, 'org_pred.npy'))\n",
    "        pred_att = np.load(os.path.join(save_dir, 'adv_pred.npy'))\n",
    "        label = np.load(os.path.join(save_dir, 'org_labels.npy'))\n",
    "        '''load heat map'''\n",
    "        hm_org = np.load(os.path.join(save_dir, 'org_hm.npy'))\n",
    "        hm_att = np.load(os.path.join(save_dir, 'adv_hm.npy'))\n",
    "        '''load images'''\n",
    "        img_org = np.load(os.path.join(save_dir, 'org_imgs.npy'))\n",
    "        img_att = np.load(os.path.join(save_dir, 'adv_imgs.npy')) \n",
    "    \n",
    "    return [img_org, img_att], [hm_org, hm_att], [pred_org, pred_att, label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87477234",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_all_metrics(model_name, xai_name, ii_specific=None):\n",
    "    img_, hm_, pred_ = load_all(model_name, xai_name, ii_specific)\n",
    "    \n",
    "    if ii_specific is None:\n",
    "        print('+++++++++++++++++++++ all images ++++++++++++++++++++')\n",
    "    else:\n",
    "        print('+++++++++++++++++++++ class {} ++++++++++++++++++++'.format(ii_specific))\n",
    "        \n",
    "    print('=== Org AUC ===')\n",
    "    auc_org = compute_metrics(pred_[0], pred_[2])['aucs']\n",
    "    print(auc_org)\n",
    "    \n",
    "    print('=== Attack AUC ===')\n",
    "    auc_att = compute_metrics(pred_[1], pred_[2])['aucs']\n",
    "    print(auc_att)\n",
    "    \n",
    "    print('=== Heat Map Org===')\n",
    "    att_index = np.where(pred_[2][:,ii_specific]==1)[0]\n",
    "    res = eval_img_similarity(hm_[0][att_index,0,:,:], hm_[1][att_index,0,:,:])\n",
    "    for _k in res.keys():\n",
    "        _v = np.nanmean(res[_k])\n",
    "        print(_k, _v)\n",
    "        if _k == 'ssim': ssim_hp_org = _v\n",
    "        if _k == 'mse': mse_hp_org = _v\n",
    "    \n",
    "    print('=== Heat Map Target===')\n",
    "    att_index = np.where(pred_[2][:,ii_specific]==1)[0]\n",
    "    attack_target_maps = np.zeros_like(hm_[0][att_index,0,:,:])\n",
    "    attack_target_maps[:, 130:190, 380:440] = 1.0/3600 # binary mask\n",
    "    res = eval_img_similarity(hm_[1][att_index,0,:,:], attack_target_maps)\n",
    "    for _k in res.keys():\n",
    "        _v = np.nanmean(res[_k])\n",
    "        print(_k, _v)\n",
    "        if _k == 'ssim': ssim_hp_att = _v\n",
    "        if _k == 'mse': mse_hp_att = _v\n",
    "    \n",
    "    print('=== Image ===')\n",
    "    res = eval_img_similarity(img_[0][:,0,:,:], img_[1][:,0,:,:])\n",
    "    for _k in res.keys():\n",
    "        _v = np.nanmean(res[_k])\n",
    "        print(_k, _v)\n",
    "        if _k == 'ssim': ssim_im = _v\n",
    "        if _k == 'mse': mse_im = _v\n",
    "            \n",
    "    return auc_org[ii_specific], auc_att[ii_specific], ssim_hp_org, mse_hp_org, ssim_hp_att, mse_hp_att, ssim_im, mse_im"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fff312b",
   "metadata": {},
   "source": [
    "### load and eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35575e03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# xai_names = ['VanillaBP']\n",
    "cfgs['output_dir'] = '/data/users/Attack_Attn/save_dir/NatComm/attack_expl'\n",
    "num_classes = len(valid_dataloader.dataset.attr_names)\n",
    "xai_names = ['VanillaBP', 'VanillaBP_Img', 'IntegratedBP', 'GradCAM', 'SmoothBP']\n",
    "model_name_list = ['resnet152', 'densenet121']\n",
    "\n",
    "for model_name in model_name_list:\n",
    "    print('-------------------------------- {} --------------------------------'.format(model_name))\n",
    "    for xai_name in xai_names:\n",
    "        print('-------------------- {} ----------------------'.format(xai_name))\n",
    "        AUC_org, AUC_att, SSIM_hp_org, MSE_hp_org, SSIM_hp_att, MSE_hp_att, SSIM_im, MSE_im = 0,0,0,0,0,0,0,0\n",
    "        for ii in np.arange(num_classes):\n",
    "            auc_org, auc_att, ssim_hp_org, mse_hp_org, ssim_hp_att, mse_hp_att, ssim_im, mse_im = eval_all_metrics(model_name, \n",
    "                                                                                                                   xai_name, ii)\n",
    "            AUC_org += auc_org/num_classes\n",
    "            AUC_att += auc_att/num_classes\n",
    "\n",
    "            SSIM_hp_org += ssim_hp_org/num_classes\n",
    "            SSIM_hp_att += ssim_hp_att/num_classes\n",
    "            SSIM_im += ssim_im/num_classes\n",
    "\n",
    "            MSE_hp_org  += mse_hp_org/num_classes\n",
    "            MSE_hp_att  += mse_hp_att/num_classes\n",
    "            MSE_im  += mse_im/num_classes\n",
    "    #     eval_all_metrics(model_name, xai_name, None)\n",
    "        print('============= averaged results of {} ============= '.format(xai_name))\n",
    "        print('AUC_org: ',AUC_org)\n",
    "        print('AUC_att: ',AUC_att)\n",
    "\n",
    "        print('SSIM_hp_org: ',SSIM_hp_org)\n",
    "        print('SSIM_hp_att: ',SSIM_hp_att)\n",
    "        print('SSIM_im: ',SSIM_im)\n",
    "\n",
    "        print('MSE_hp_org: ',MSE_hp_org)\n",
    "        print('MSE_hp_att: ',MSE_hp_att)\n",
    "        print('MSE_im: ',MSE_im)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e831a6d4",
   "metadata": {},
   "source": [
    "### Compute and save heatmap of G-GradCAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4aedaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfgs['output_dir'] = '/data/users/Attack_Attn/save_dir/NatComm/attack_expl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84363889",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {'0': [1., 0., 0., 0., 0.],\n",
    "              '1': [0., 1., 0., 0., 0.],\n",
    "              '2': [0., 0., 1., 0., 0.],\n",
    "              '3': [0., 0., 0., 1., 0.],\n",
    "              '4': [0., 0., 0., 0., 1.]}\n",
    "\n",
    "'''init model'''\n",
    "dense121_cfgs = {\n",
    "    'model_info':{\n",
    "        'model_name': 'densenet121',\n",
    "        'model_path': '/home/Attack_Attn/ChestXpert/save_dir_multimodel/densenet121_5c/best_checkpoints/checkpoint_9.pt',\n",
    "#         'model_path': '/home/Attack_Attn/ChestXpert/save_dir_multimodel/densenet121_weakrobust/best_checkpoints/checkpoint_9.pt',\n",
    "#         'model_path': '/home/Attack_Attn/ChestXpert/save_dir_multimodel/robust_densenet121/best_checkpoints/checkpoint_9.pt',\n",
    "    },\n",
    "    'exp_method': 'GuidedGradCAM',\n",
    "    'exp_cfgs':{\n",
    "        'target_layer': ['features','denseblock4','denselayer14'],\n",
    "    }\n",
    "}\n",
    "\n",
    "model_cfgs = {}\n",
    "model_cfgs['src_models']=[\n",
    "    dense121_cfgs,\n",
    "#     mobilV2_cfgs,\n",
    "#     res152_cfgs,\n",
    "]\n",
    "model_cfgs['tgt_models']=[\n",
    "#     res152_cfgs,\n",
    "]\n",
    "model_cfgs['pretrained'] = False\n",
    "cfgs['model'] = model_cfgs\n",
    "source_exp_models = [expmodel_factory(model_cfgs, cfgs) for model_cfgs in cfgs['model']['src_models']]\n",
    "\n",
    "\n",
    "'''load data from GradCAM'''\n",
    "xai_names =  ['VanillaBP', 'VanillaBP_Img', 'GuidedBP', 'IntegratedBP', 'GradCAM', 'GuidedGradCAM', 'SmoothBP', 'XRAI']\n",
    "model_name = 'densenet121'\n",
    "img_, hm_, pred_ = load_all(model_name='densenet121', xai_name='GradCAM', ii_specific=1)\n",
    "print(img_[0].shape) # original image\n",
    "print(img_[1].shape) # adversarial image\n",
    "# image_num, _, _, _ = img_[0].shape\n",
    "# print(image_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bead5dc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for ii in np.arange(5): # 5 different classes\n",
    "    print('==================== calss number: {} ===================='.format(ii))\n",
    "    hm_org, hm_att = [], []\n",
    "    img_, hm_, pred_ = load_all(model_name='densenet121', xai_name='GradCAM', ii_specific=ii)\n",
    "    image_num, _, _, _ = img_[0].shape\n",
    "    save_dir = os.path.join(cfgs['output_dir'], \n",
    "                            model_cfgs['src_models'][0]['model_info']['model_name']+'_'+\\\n",
    "                            model_cfgs['src_models'][0]['exp_method']+\\\n",
    "                            '_class_'+str(ii))\n",
    "    class_of_interest = label_dict[str(ii)]\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    for img_index in np.arange(image_num):\n",
    "        print('---- img_index: {} ----'.format(img_index))\n",
    "        img_org = torch.Tensor(img_[0][img_index]).clone().detach()\n",
    "        img_adv = torch.Tensor(img_[1][img_index]).clone().detach()\n",
    "#         class_of_interest = torch.Tensor(pred_[2][0])\n",
    "#         print(img_org.size())\n",
    "        res_org = [_.cal_exp_map(img_org.to(torch.device(cfgs['device'])).unsqueeze(0), class_of_interest) for _ in source_exp_models]\n",
    "        res_adv = [_.cal_exp_map(img_adv.to(torch.device(cfgs['device'])).unsqueeze(0), class_of_interest) for _ in source_exp_models]\n",
    "\n",
    "        hm_org.append(res_org[0][0].data.cpu())\n",
    "        hm_att.append(res_adv[0][0].data.cpu())\n",
    "        del res_org, res_adv\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    '''save npy images'''\n",
    "    hm_org = torch.cat(hm_org, dim=0).unsqueeze_(1)\n",
    "    hm_att = torch.cat(hm_att, dim=0).unsqueeze_(1)\n",
    "    print(hm_org.shape)\n",
    "    \n",
    "    np.save(os.path.join(save_dir, 'hm_org.npy'), hm_org.numpy())\n",
    "    np.save(os.path.join(save_dir, 'hm_att.npy'), hm_att.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1920ff",
   "metadata": {},
   "source": [
    "### Compute and save heatmap of XRAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819a1600",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {'0': [1., 0., 0., 0., 0.],\n",
    "              '1': [0., 1., 0., 0., 0.],\n",
    "              '2': [0., 0., 1., 0., 0.],\n",
    "              '3': [0., 0., 0., 1., 0.],\n",
    "              '4': [0., 0., 0., 0., 1.]}\n",
    "\n",
    "'''init model'''\n",
    "dense121_cfgs = {\n",
    "    'model_info':{\n",
    "        'model_name': 'densenet121',\n",
    "        'model_path': '/home/Attack_Attn/ChestXpert/save_dir_multimodel/densenet121_5c/best_checkpoints/checkpoint_9.pt',\n",
    "#         'model_path': '/home/Attack_Attn/ChestXpert/save_dir_multimodel/densenet121_weakrobust/best_checkpoints/checkpoint_9.pt',\n",
    "#         'model_path': '/home/Attack_Attn/ChestXpert/save_dir_multimodel/robust_densenet121/best_checkpoints/checkpoint_9.pt',\n",
    "    },\n",
    "    'exp_method': 'XRAI',\n",
    "    'exp_cfgs':{\n",
    "#         'target_layer': ['features','denseblock4','denselayer14'],\n",
    "    }\n",
    "}\n",
    "\n",
    "model_cfgs = {}\n",
    "model_cfgs['src_models']=[\n",
    "    dense121_cfgs,\n",
    "#     mobilV2_cfgs,\n",
    "#     res152_cfgs,\n",
    "]\n",
    "model_cfgs['tgt_models']=[\n",
    "#     res152_cfgs,\n",
    "]\n",
    "model_cfgs['pretrained'] = False\n",
    "cfgs['model'] = model_cfgs\n",
    "source_exp_models = [expmodel_factory(model_cfgs, cfgs) for model_cfgs in cfgs['model']['src_models']]\n",
    "\n",
    "\n",
    "'''load data from GradCAM'''\n",
    "xai_names =  ['VanillaBP', 'VanillaBP_Img', 'GuidedBP', 'IntegratedBP', 'GradCAM', 'GuidedGradCAM', 'SmoothBP', 'XRAI']\n",
    "model_name = 'densenet121'\n",
    "img_, hm_, pred_ = load_all(model_name='densenet121', xai_name='IntegratedBP', ii_specific=1)\n",
    "print(img_[0].shape) # original image\n",
    "print(img_[1].shape) # adversarial image\n",
    "# image_num, _, _, _ = img_[0].shape\n",
    "# print(image_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2c6066",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in np.arange(5): # 5 different classes\n",
    "    print('==================== calss number: {} ===================='.format(ii))\n",
    "    hm_org, hm_att = [], []\n",
    "    img_, hm_, pred_ = load_all(model_name='densenet121', xai_name='IntegratedBP', ii_specific=ii)\n",
    "    image_num, _, _, _ = img_[0].shape\n",
    "    save_dir = os.path.join(cfgs['output_dir'], \n",
    "                            model_cfgs['src_models'][0]['model_info']['model_name']+'_'+\\\n",
    "                            model_cfgs['src_models'][0]['exp_method']+\\\n",
    "                            '_class_'+str(ii))\n",
    "    class_of_interest = label_dict[str(ii)]\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    for img_index in np.arange(image_num):\n",
    "        print('---- img_index: {} ----'.format(img_index))\n",
    "        img_org = torch.Tensor(img_[0][img_index]).clone().detach()\n",
    "        img_adv = torch.Tensor(img_[1][img_index]).clone().detach()\n",
    "#         class_of_interest = torch.Tensor(pred_[2][0])\n",
    "#         print(img_org.size())\n",
    "        res_org = [_.cal_exp_map(img_org.to(torch.device(cfgs['device'])).unsqueeze(0), class_of_interest) for _ in source_exp_models]\n",
    "        res_adv = [_.cal_exp_map(img_adv.to(torch.device(cfgs['device'])).unsqueeze(0), class_of_interest) for _ in source_exp_models]\n",
    "\n",
    "        hm_org.append(torch.Tensor(res_org[0][0]).unsqueeze_(0))\n",
    "        hm_att.append(torch.Tensor(res_adv[0][0]).unsqueeze_(0))\n",
    "        del res_org, res_adv\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    '''save npy images'''\n",
    "    hm_org = torch.cat(hm_org, dim=0).unsqueeze_(1)\n",
    "    hm_att = torch.cat(hm_att, dim=0).unsqueeze_(1)\n",
    "    print(hm_org.shape)\n",
    "    \n",
    "    np.save(os.path.join(save_dir, 'hm_org.npy'), hm_org.numpy())\n",
    "    np.save(os.path.join(save_dir, 'hm_att.npy'), hm_att.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fd05a6",
   "metadata": {},
   "source": [
    "### eval G-GradCAM and XRAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5693f870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all__(model_name, xai_name, ii_specific=None):\n",
    "#     model_name = model_cfgs['src_models'][0]['model_info']['model_name']\n",
    "#     xai_name = model_cfgs['src_models'][0]['exp_method']\n",
    "    hm_org, hm_att = [], []\n",
    "    \n",
    "    if ii_specific is None:\n",
    "        for ii in np.arange(5):\n",
    "            save_dir = os.path.join(cfgs['output_dir'], \n",
    "                                    model_cfgs['src_models'][0]['model_info']['model_name']+'_'+\\\n",
    "                                    xai_name+\\\n",
    "                                    '_class_'+str(ii))\n",
    "            '''load heat map'''\n",
    "            hm_org.append(np.load(os.path.join(save_dir, 'hm_org.npy')))\n",
    "            hm_att.append(np.load(os.path.join(save_dir, 'hm_att.npy')))\n",
    "\n",
    "        hm_org = np.concatenate(hm_org, 0)\n",
    "        hm_att = np.concatenate(hm_att, 0)\n",
    "    else:\n",
    "        save_dir = os.path.join(cfgs['output_dir'], \n",
    "                                    model_cfgs['src_models'][0]['model_info']['model_name']+'_'+\\\n",
    "                                    xai_name+\\\n",
    "                                    '_class_'+str(ii_specific))\n",
    "        '''load heat map'''\n",
    "        hm_org = np.load(os.path.join(save_dir, 'hm_org.npy'))\n",
    "        hm_att = np.load(os.path.join(save_dir, 'hm_att.npy'))\n",
    "    \n",
    "    return [hm_org, hm_att]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14189c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_all_metrics__(model_name, xai_name, ii_specific=None):\n",
    "    hm_ = load_all__(model_name, xai_name, ii_specific)\n",
    "    if xai_name == 'GuidedGradCAM':\n",
    "        img_, _, pred_ = load_all(model_name, 'GradCAM', ii_specific)\n",
    "    if xai_name == 'XRAI':\n",
    "        img_, _, pred_ = load_all(model_name, 'IntegratedBP', ii_specific)\n",
    "    if ii_specific is None:\n",
    "        print('+++++++++++++++++++++ all images ++++++++++++++++++++')\n",
    "    else:\n",
    "        print('+++++++++++++++++++++ class {} ++++++++++++++++++++'.format(ii_specific))\n",
    "        \n",
    "    print('=== Heat Map Org===')\n",
    "    att_index = np.where(pred_[2][:,ii_specific]==1)[0]\n",
    "    res = eval_img_similarity(hm_[0][att_index,0,:,:], hm_[1][att_index,0,:,:])\n",
    "    for _k in res.keys():\n",
    "        print(_k, np.nanmean(res[_k]))\n",
    "        \n",
    "    print('=== Heat Map Target===')\n",
    "    att_index = np.where(pred_[2][:,ii_specific]==1)[0]\n",
    "    attack_target_maps = np.zeros_like(hm_[0][att_index,0,:,:])\n",
    "    attack_target_maps[:, 130:190, 380:440] = 1.0/3600 # binary mask\n",
    "    res = eval_img_similarity(hm_[1][att_index,0,:,:], attack_target_maps)\n",
    "    for _k in res.keys():\n",
    "        print(_k, np.nanmean(res[_k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a02d8a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xai_names =  ['GuidedGradCAM', 'XRAI']\n",
    "model_name = 'densenet121'\n",
    "for xai_name in xai_names:\n",
    "    print('-------------------------------- {} --------------------------------'.format(xai_name))\n",
    "    for ii in np.arange(5):\n",
    "        eval_all_metrics__(model_name, xai_name, ii)\n",
    "#     eval_all_metrics__(model_name, xai_name, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5c6faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ii_specific_ = 4\n",
    "_, _, pred_ = load_all(model_name='densenet121', xai_name='IntegratedBP', ii_specific=ii_specific_)\n",
    "hm_ = load_all__(model_name='densenet121', xai_name='XRAI', ii_specific=ii_specific_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6b0eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5d2ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.where(pred_[2][:,ii_specific_]==1)[0]\n",
    "partial = hm_[0][index,0,:,:]\n",
    "print(partial.shape)\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a2e3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hm_org, hm_att = hm_[0], hm_[1]\n",
    "print(hm_org[0,0].shape, hm_att.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c533676a",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = eval_img_similarity(hm_org[index,0,:,:], hm_att[index,0,:,:])\n",
    "for _k in res.keys():\n",
    "        print(_k, np.nanmean(res[_k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0043f3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "kk = 17\n",
    "plt.imshow(hm_org[index[kk],0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63907317",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(hm_att[index[kk],0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396af130",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "189e7913",
   "metadata": {},
   "source": [
    "## Compute PSC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad04163",
   "metadata": {},
   "source": [
    "###  Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5b869f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all(output_dir, model_name, xai_name, ii_specific=None):\n",
    "#     model_name = model_cfgs['src_models'][0]['model_info']['model_name']\n",
    "#     xai_name = model_cfgs['src_models'][0]['exp_method']\n",
    "    img_org, img_att = [], []\n",
    "    pred_org, pred_att, label = [], [], []\n",
    "    hm_org, hm_att = [], []\n",
    "    \n",
    "    if ii_specific is None:\n",
    "        for ii in np.arange(5):\n",
    "            save_dir = os.path.join(output_dir, \n",
    "                                    model_name+'_'+\\\n",
    "                                    xai_name+\\\n",
    "                                    '_class_'+str(ii))\n",
    "            '''load predictions'''\n",
    "            pred_org.append(np.load(os.path.join(save_dir, 'org_pred.npy')))\n",
    "            pred_att.append(np.load(os.path.join(save_dir, 'adv_pred.npy')))\n",
    "            label.append(np.load(os.path.join(save_dir, 'org_labels.npy')))\n",
    "            '''load heat map'''\n",
    "            hm_org.append(np.load(os.path.join(save_dir, 'org_hm.npy')))\n",
    "            hm_att.append(np.load(os.path.join(save_dir, 'adv_hm.npy')))\n",
    "            '''load images'''\n",
    "            img_org.append(np.load(os.path.join(save_dir, 'org_imgs.npy')))\n",
    "            img_att.append(np.load(os.path.join(save_dir, 'adv_imgs.npy')))\n",
    "\n",
    "        pred_org = np.concatenate(pred_org, 0)\n",
    "        pred_att = np.concatenate(pred_att, 0)\n",
    "        label = np.concatenate(label, 0)\n",
    "\n",
    "        hm_org = np.concatenate(hm_org, 0)\n",
    "        hm_att = np.concatenate(hm_att, 0)\n",
    "\n",
    "        img_org = np.concatenate(img_org, 0)\n",
    "        img_att = np.concatenate(img_att, 0)\n",
    "    else:\n",
    "        save_dir = os.path.join(output_dir, \n",
    "                                model_name+'_'+\\\n",
    "                                xai_name+\\\n",
    "                                '_class_'+str(ii_specific))\n",
    "        '''load predictions'''\n",
    "        pred_org = np.load(os.path.join(save_dir, 'org_pred.npy'))\n",
    "        pred_att = np.load(os.path.join(save_dir, 'adv_pred.npy'))\n",
    "        label = np.load(os.path.join(save_dir, 'org_labels.npy'))\n",
    "        '''load heat map'''\n",
    "        hm_org = np.load(os.path.join(save_dir, 'org_hm.npy'))\n",
    "        hm_att = np.load(os.path.join(save_dir, 'adv_hm.npy'))\n",
    "        '''load images'''\n",
    "        img_org = np.load(os.path.join(save_dir, 'org_imgs.npy'))\n",
    "        img_att = np.load(os.path.join(save_dir, 'adv_imgs.npy')) \n",
    "    \n",
    "    return [img_org, img_att], [hm_org, hm_att], [pred_org, pred_att, label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c8548c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_all_metrics(model_name, xai_name, ii_specific=None):\n",
    "    img_, hm_, pred_ = load_all(model_name, xai_name, ii_specific)\n",
    "    if ii_specific is None:\n",
    "        print('+++++++++++++++++++++ all images ++++++++++++++++++++')\n",
    "    else:\n",
    "        print('+++++++++++++++++++++ class {} ++++++++++++++++++++'.format(ii_specific))\n",
    "    print('=== Org AUC ===')\n",
    "    print(compute_metrics(pred_[0], pred_[2])['aucs'])\n",
    "    print('=== Attack AUC ===')\n",
    "    print(compute_metrics(pred_[1], pred_[2])['aucs'])\n",
    "    \n",
    "    print('=== Heat Map ===')\n",
    "    res = eval_img_similarity(hm_[0][:,0,:,:], hm_[1][:,0,:,:])\n",
    "    for _k in res.keys():\n",
    "        print(_k, np.nanmean(res[_k]))\n",
    "    \n",
    "    print('=== Image ===')\n",
    "    res = eval_img_similarity(img_[0][:,0,:,:], img_[1][:,0,:,:])\n",
    "    for _k in res.keys():\n",
    "        print(_k, np.nanmean(res[_k]))\n",
    "    \n",
    "    print('=== JSD-PRED ===')\n",
    "    jsd = compute_jsd(pred_[0], pred_[1], ii_specific)\n",
    "    print(jsd.mean())\n",
    "    print('=== JSD-HM ===')\n",
    "    jsd = compute_jsd(hm_[0], hm_[1], ii_specific)\n",
    "    print(jsd.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7176f31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_jsd(pred_org, pred_adv, class_of_interest):\n",
    "    \n",
    "    pred_org, pred_adv = torch.Tensor(pred_org), torch.Tensor(pred_adv)\n",
    "    if len(pred_org.shape) == 4: #image data\n",
    "#         print('image')\n",
    "        prob_org, prob_adv = torch.flatten(pred_org, start_dim=1), torch.flatten(pred_adv, start_dim=1)\n",
    "        prob_mean = torch.clamp((prob_org + prob_adv) / 2., 1e-7, 1).log()\n",
    "#         print(prob_mean.shape)\n",
    "        kld1 = F.kl_div(prob_mean, prob_org, reduction=\"none\").sum(1)\n",
    "        kld2 = F.kl_div(prob_mean, prob_adv, reduction=\"none\").sum(1)\n",
    "    else: # logits data\n",
    "#         print('logits')\n",
    "        prob_org, prob_adv = torch.sigmoid(pred_org), torch.sigmoid(pred_adv)\n",
    "        prob_org_intr, prob_adv_intr = prob_org[:,class_of_interest].unsqueeze(1), prob_adv[:,class_of_interest].unsqueeze(1)\n",
    "\n",
    "        prob_org_binary = torch.cat([prob_org_intr, 1-prob_org_intr], dim=1)\n",
    "        prob_adv_binary = torch.cat([prob_adv_intr, 1-prob_adv_intr], dim=1)\n",
    "        prob_mean = torch.clamp((prob_org_binary + prob_adv_binary) / 2., 1e-7, 1).log()\n",
    "\n",
    "        kld1 = F.kl_div(prob_mean, prob_org_binary, reduction=\"none\").sum(1)\n",
    "        kld2 = F.kl_div(prob_mean, prob_adv_binary, reduction=\"none\").sum(1)\n",
    "    jsd = (kld1 + kld2) * 0.5\n",
    "    return jsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b021b03b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### load pred attack\n",
    "# ['VanillaBP', 'VanillaBP_Img', 'GuidedBP', 'IntegratedBP', 'GradCAM', 'GuidedGradCAM', 'SmoothBP', 'XRAI']\n",
    "num_classes = len(valid_dataloader.dataset.attr_names)\n",
    "model_list = ['densenet121', 'resnet152']\n",
    "xai_list = ['VanillaBP', 'VanillaBP_Img', 'IntegratedBP', 'GradCAM', 'SmoothBP']\n",
    "pred_att_dir = '/data/users/Attack_Attn/save_dir/NatComm/attack_pred'\n",
    "expl_att_dir = '/data/users/Attack_Attn/save_dir/NatComm/attack_expl'\n",
    "\n",
    "for model_ in model_list:\n",
    "# model_='resnet152'\n",
    "    print('++++++++++++++++ Model: {} ++++++++++++++++'.format(model_))\n",
    "    for xai_ in xai_list:\n",
    "# xai_='GradCAM'\n",
    "        print('========= {} ========='.format(xai_))\n",
    "        psc_pred, psc_expl = 0, 0\n",
    "        for class_index in np.arange(num_classes):\n",
    "# class_index=1\n",
    "            '''eval pred attack'''\n",
    "            pred_img_, pred_hm_, pred_lab_ = load_all(output_dir=pred_att_dir, \n",
    "                                                      model_name=model_, \n",
    "                                                      xai_name=xai_, \n",
    "                                                      ii_specific=class_index)\n",
    "            pred_lab_jsd = compute_jsd(pred_org=pred_lab_[0], \n",
    "                                       pred_adv=pred_lab_[1], \n",
    "                                       class_of_interest=class_index)\n",
    "            pred_hm_jsd = compute_jsd(pred_org=pred_hm_[0], \n",
    "                                      pred_adv=pred_hm_[1], \n",
    "                                      class_of_interest=class_index)\n",
    "            pred_lab_jsd_np = np.asarray(pred_lab_jsd.numpy())\n",
    "            pred_hm_jsd_np = np.asarray(pred_hm_jsd.numpy())\n",
    "            pred_hm_jsd_np[np.isnan(pred_hm_jsd_np)] = np.nanmean(pred_hm_jsd_np)\n",
    "            psc_pred += pearsonr(pred_lab_jsd_np, pred_hm_jsd_np)[0]/num_classes\n",
    "\n",
    "            '''eval expl attack'''\n",
    "            expl_img_, expl_hm_, expl_lab_ = load_all(output_dir=expl_att_dir, \n",
    "                                                     model_name=model_, \n",
    "                                                     xai_name=xai_, \n",
    "                                                     ii_specific=class_index)\n",
    "            att_index = np.where(expl_lab_[2][:,class_index]==1)[0]\n",
    "            expl_lab_jsd = compute_jsd(pred_org=expl_lab_[0][att_index,:], \n",
    "                                       pred_adv=expl_lab_[1][att_index,:], \n",
    "                                       class_of_interest=class_index)\n",
    "            expl_hm_jsd = compute_jsd(pred_org=expl_hm_[0][att_index,:], \n",
    "                                      pred_adv=expl_hm_[1][att_index,:], \n",
    "                                      class_of_interest=class_index)\n",
    "            expl_lab_jsd_np = np.asarray(expl_lab_jsd.numpy())\n",
    "            expl_hm_jsd_np = np.asarray(expl_hm_jsd.numpy())\n",
    "            expl_hm_jsd_np[np.isnan(expl_hm_jsd_np)] = np.nanmean(expl_hm_jsd_np)\n",
    "            psc_expl += pearsonr(expl_lab_jsd_np, expl_hm_jsd_np)[0]/num_classes\n",
    "        print('pred psc: {},   expl psc: {}'.format(psc_pred, psc_expl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9767fc3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64463016",
   "metadata": {},
   "source": [
    "# Cross XAI transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486a5ac9",
   "metadata": {},
   "source": [
    "## PRED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874bc4a7",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def load_all(output_dir, model_name, xai_name, ii_specific=None):\n",
    "#     model_name = model_cfgs['src_models'][0]['model_info']['model_name']\n",
    "#     xai_name = model_cfgs['src_models'][0]['exp_method']\n",
    "    img_org, img_att = [], []\n",
    "    pred_org, pred_att, label = [], [], []\n",
    "    hm_org, hm_att = [], []\n",
    "    \n",
    "    if ii_specific is None:\n",
    "        for ii in np.arange(5):\n",
    "            save_dir = os.path.join(output_dir, \n",
    "                                    model_name+'_'+\\\n",
    "                                    xai_name+\\\n",
    "                                    '_class_'+str(ii))\n",
    "            '''load predictions'''\n",
    "            pred_org.append(np.load(os.path.join(save_dir, 'org_pred.npy')))\n",
    "            pred_att.append(np.load(os.path.join(save_dir, 'adv_pred.npy')))\n",
    "            label.append(np.load(os.path.join(save_dir, 'org_labels.npy')))\n",
    "            '''load heat map'''\n",
    "            hm_org.append(np.load(os.path.join(save_dir, 'org_hm.npy')))\n",
    "            hm_att.append(np.load(os.path.join(save_dir, 'adv_hm.npy')))\n",
    "            '''load images'''\n",
    "            img_org.append(np.load(os.path.join(save_dir, 'org_imgs.npy')))\n",
    "            img_att.append(np.load(os.path.join(save_dir, 'adv_imgs.npy')))\n",
    "\n",
    "        pred_org = np.concatenate(pred_org, 0)\n",
    "        pred_att = np.concatenate(pred_att, 0)\n",
    "        label = np.concatenate(label, 0)\n",
    "\n",
    "        hm_org = np.concatenate(hm_org, 0)\n",
    "        hm_att = np.concatenate(hm_att, 0)\n",
    "\n",
    "        img_org = np.concatenate(img_org, 0)\n",
    "        img_att = np.concatenate(img_att, 0)\n",
    "    else:\n",
    "        save_dir = os.path.join(output_dir, \n",
    "                                model_name+'_'+\\\n",
    "                                xai_name+\\\n",
    "                                '_class_'+str(ii_specific))\n",
    "        '''load predictions'''\n",
    "        pred_org = np.load(os.path.join(save_dir, 'org_pred.npy'))\n",
    "        pred_att = np.load(os.path.join(save_dir, 'adv_pred.npy'))\n",
    "        label = np.load(os.path.join(save_dir, 'org_labels.npy'))\n",
    "        '''load heat map'''\n",
    "        hm_org = np.load(os.path.join(save_dir, 'org_hm.npy'))\n",
    "        hm_att = np.load(os.path.join(save_dir, 'adv_hm.npy'))\n",
    "        '''load images'''\n",
    "        img_org = np.load(os.path.join(save_dir, 'org_imgs.npy'))\n",
    "        img_att = np.load(os.path.join(save_dir, 'adv_imgs.npy')) \n",
    "    \n",
    "    return [img_org, img_att], [hm_org, hm_att], [pred_org, pred_att, label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d664730",
   "metadata": {},
   "outputs": [],
   "source": [
    "xai_namelist = ['VanillaBP', 'VanillaBP_Img', 'GradCAM', 'GuidedGradCAM', 'SmoothBP', 'XRAI']\n",
    "src_xai = 'IntegratedBP'\n",
    "model_name = 'resnet152' #'densenet121'\n",
    "\n",
    "label_dict = {'0': [1., 0., 0., 0., 0.],\n",
    "              '1': [0., 1., 0., 0., 0.],\n",
    "              '2': [0., 0., 1., 0., 0.],\n",
    "              '3': [0., 0., 0., 1., 0.],\n",
    "              '4': [0., 0., 0., 0., 1.]}\n",
    "\n",
    "cfgs['data_dir'] = '/data/users/Attack_Attn/save_dir/NatComm/attack_pred/'\n",
    "cfgs['save_dir'] = '/data/users/Attack_Attn/save_dir/NatComm/ig_attack_pred/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d4a167",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for xai_name in xai_namelist:\n",
    "    # xai_name = xai_namelist[0]\n",
    "    '''init model'''\n",
    "    if model_name == 'densenet121':\n",
    "        if xai_name in ['GradCAM', 'GuidedGradCAM']:\n",
    "            dense121_cfgs = {\n",
    "                'model_info':{\n",
    "                    'model_name': model_name,\n",
    "                    'model_path': '/home/Attack_Attn/ChestXpert/save_dir_multimodel/densenet121_5c/best_checkpoints/checkpoint_9.pt',\n",
    "                },\n",
    "                'exp_method': xai_name,\n",
    "                'exp_cfgs':{\n",
    "                    'target_layer': ['features','denseblock4','denselayer14'],\n",
    "                }\n",
    "            }\n",
    "        else:\n",
    "            dense121_cfgs = {\n",
    "                'model_info':{\n",
    "                    'model_name': model_name,\n",
    "                    'model_path': '/home/Attack_Attn/ChestXpert/save_dir_multimodel/densenet121_5c/best_checkpoints/checkpoint_9.pt',\n",
    "                },\n",
    "                'exp_method': xai_name,\n",
    "                'exp_cfgs':{\n",
    "            #         'target_layer': ['features','denseblock4','denselayer14'],\n",
    "                }\n",
    "            }\n",
    "        model_cfgs = {}\n",
    "        model_cfgs['src_models']=[\n",
    "            dense121_cfgs,\n",
    "        ]\n",
    "        model_cfgs['pretrained'] = False\n",
    "        cfgs['model'] = model_cfgs\n",
    "        \n",
    "    elif model_name == 'resnet152':\n",
    "        if xai_name in ['GradCAM', 'GuidedGradCAM']:\n",
    "            res152_cfgs = {\n",
    "                'model_info':{\n",
    "                    'model_name': model_name,\n",
    "                    'model_path': '/home/Attack_Attn/ChestXpert/save_dir_multimodel/resnet152_5c/best_checkpoints/checkpoint_5.pt',\n",
    "                },\n",
    "                'exp_method': xai_name,\n",
    "                'exp_cfgs':{\n",
    "                    'target_layer': ['layer4','2'],\n",
    "                }\n",
    "            }\n",
    "        else:\n",
    "            res152_cfgs = {\n",
    "                'model_info':{\n",
    "                    'model_name': model_name,\n",
    "                    'model_path': '/home/Attack_Attn/ChestXpert/save_dir_multimodel/resnet152_5c/best_checkpoints/checkpoint_5.pt',\n",
    "                },\n",
    "                'exp_method': xai_name,\n",
    "                'exp_cfgs':{\n",
    "#                     'target_layer': ['layer4','2'],\n",
    "                }\n",
    "            }\n",
    "        model_cfgs = {}\n",
    "        model_cfgs['src_models']=[\n",
    "            res152_cfgs,\n",
    "        ]\n",
    "        model_cfgs['pretrained'] = False\n",
    "        cfgs['model'] = model_cfgs\n",
    "    \n",
    "    \n",
    "    source_exp_models = [expmodel_factory(model_cfgs, cfgs) for model_cfgs in cfgs['model']['src_models']]\n",
    "\n",
    "    for ii in np.arange(5): # 5 different classes\n",
    "        # ii = 0\n",
    "        print('============== calss number: {} ==============='.format(ii))\n",
    "        '''load data from IG folder'''\n",
    "        hm_org, hm_att = [], []\n",
    "        img_, _, _ = load_all(output_dir=cfgs['data_dir'], \n",
    "                            model_name=model_cfgs['src_models'][0]['model_info']['model_name'], \n",
    "                            xai_name=src_xai, \n",
    "                            ii_specific=ii)\n",
    "\n",
    "        image_num, _, _, _ = img_[0].shape\n",
    "        save_dir = os.path.join(cfgs['save_dir'], \n",
    "                                model_cfgs['src_models'][0]['model_info']['model_name']+'_'+\\\n",
    "                                xai_name+\\\n",
    "                                '_class_'+str(ii))\n",
    "        class_of_interest = label_dict[str(ii)]\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "        for img_index in np.arange(image_num):\n",
    "            print('---- img_index: {} ----'.format(img_index))\n",
    "            img_org = torch.Tensor(img_[0][img_index]).clone().detach()\n",
    "            img_adv = torch.Tensor(img_[1][img_index]).clone().detach()\n",
    "\n",
    "            res_org = [_.cal_exp_map(img_org.to(torch.device(cfgs['device'])).unsqueeze(0), class_of_interest) for _ in source_exp_models]\n",
    "            res_adv = [_.cal_exp_map(img_adv.to(torch.device(cfgs['device'])).unsqueeze(0), class_of_interest) for _ in source_exp_models]\n",
    "            \n",
    "            if xai_name == 'XRAI':\n",
    "                hm_org.append(torch.Tensor(res_org[0][0]).unsqueeze_(0))\n",
    "                hm_att.append(torch.Tensor(res_adv[0][0]).unsqueeze_(0))\n",
    "            else:\n",
    "                hm_org.append(res_org[0][0].data.cpu())\n",
    "                hm_att.append(res_adv[0][0].data.cpu())\n",
    "            del res_org, res_adv\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        '''save npy images'''\n",
    "        hm_org = torch.cat(hm_org, dim=0).unsqueeze_(1)\n",
    "        hm_att = torch.cat(hm_att, dim=0).unsqueeze_(1)\n",
    "        print(hm_org.shape)\n",
    "\n",
    "        np.save(os.path.join(save_dir, 'hm_org.npy'), hm_org.numpy())\n",
    "        np.save(os.path.join(save_dir, 'hm_att.npy'), hm_att.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a573e0ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ab72149",
   "metadata": {},
   "source": [
    "### Eval-PRED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc828f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfgs['output_dir'] = '/data/users/Attack_Attn/save_dir/NatComm/ig_attack_pred/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5cc4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_jsd(pred_org, pred_adv, class_of_interest):\n",
    "    \n",
    "    pred_org, pred_adv = torch.Tensor(pred_org), torch.Tensor(pred_adv)\n",
    "    if len(pred_org.shape) == 4: #image data\n",
    "#         print('image')\n",
    "        prob_org, prob_adv = torch.flatten(pred_org, start_dim=1), torch.flatten(pred_adv, start_dim=1)\n",
    "        prob_mean = torch.clamp((prob_org + prob_adv) / 2., 1e-7, 1).log()\n",
    "#         print(prob_mean.shape)\n",
    "        kld1 = F.kl_div(prob_mean, prob_org, reduction=\"none\").sum(1)\n",
    "        kld2 = F.kl_div(prob_mean, prob_adv, reduction=\"none\").sum(1)\n",
    "    else: # logits data\n",
    "#         print('logits')\n",
    "        prob_org, prob_adv = torch.sigmoid(pred_org), torch.sigmoid(pred_adv)\n",
    "        prob_org_intr, prob_adv_intr = prob_org[:,class_of_interest].unsqueeze(1), prob_adv[:,class_of_interest].unsqueeze(1)\n",
    "\n",
    "        prob_org_binary = torch.cat([prob_org_intr, 1-prob_org_intr], dim=1)\n",
    "        prob_adv_binary = torch.cat([prob_adv_intr, 1-prob_adv_intr], dim=1)\n",
    "        prob_mean = torch.clamp((prob_org_binary + prob_adv_binary) / 2., 1e-7, 1).log()\n",
    "\n",
    "        kld1 = F.kl_div(prob_mean, prob_org_binary, reduction=\"none\").sum(1)\n",
    "        kld2 = F.kl_div(prob_mean, prob_adv_binary, reduction=\"none\").sum(1)\n",
    "    jsd = (kld1 + kld2) * 0.5\n",
    "    return jsd\n",
    "\n",
    "\n",
    "def eval_img_similarity(imgs_1, imgs_2):\n",
    "    assert len(imgs_1.shape) == len(imgs_2.shape) == 3\n",
    "    ssim_vals = []\n",
    "    pcc_vals = []\n",
    "    imgs_1 = batch_img_norm(imgs_1) * 255\n",
    "    imgs_2 = batch_img_norm(imgs_2) * 255\n",
    "    for i in range(imgs_1.shape[0]):\n",
    "        _img1 = imgs_1[i]\n",
    "        _img2 = imgs_2[i]\n",
    "        if np.isnan(_img1.mean()) or np.isnan(_img2.mean()):\n",
    "            print(i)\n",
    "            continue\n",
    "        \n",
    "        # SSIM\n",
    "        _ssim, _ = ssim(_img1, _img2, data_range=255, full=True, multichannel=False)\n",
    "        ssim_vals.append(_ssim)\n",
    "        \n",
    "        # PCC\n",
    "        _pcc = pearsonr(_img1.reshape(-1), _img2.reshape(-1))[0]\n",
    "        pcc_vals.append(_pcc)\n",
    "    \n",
    "    # MSE\n",
    "    mse_vals = np.nanmean(((imgs_1/255 - imgs_2/255)**2).mean(-1))\n",
    "    return {\n",
    "        'ssim': np.asarray(ssim_vals),\n",
    "        'mse': mse_vals,\n",
    "        'pcc': np.asarray(pcc_vals),\n",
    "    }\n",
    "\n",
    "\n",
    "def eval_all_metrics(output_dir, model_name, xai_name, ii_specific=None):\n",
    "    hm_org, hm_att = load_all_tgt(output_dir, model_name, xai_name, ii_specific) \n",
    "    print(hm_org.shape, hm_att.shape)\n",
    "    if ii_specific is None:\n",
    "        print('+++++++++++++++++++++ all images ++++++++++++++++++++')\n",
    "    else:\n",
    "        print('+++++++++++++++++++++ class {} ++++++++++++++++++++'.format(ii_specific))\n",
    "    \n",
    "    print('=== Heat Map ===')\n",
    "    res = eval_img_similarity(hm_org[:,0,:,:], hm_att[:,0,:,:])\n",
    "    for _k in res.keys():\n",
    "        _v = np.nanmean(res[_k])\n",
    "        print(_k, _v)\n",
    "        if _k == 'ssim': ssim_hp = _v\n",
    "        if _k == 'mse': mse_hp = _v\n",
    "            \n",
    "    return ssim_hp, mse_hp\n",
    "\n",
    "\n",
    "\n",
    "def load_all_src(output_dir, model_name, xai_name, ii_specific=None):\n",
    "    '''load predictions'''\n",
    "    hm_org, hm_att = [], []\n",
    "    if ii_specific is None:\n",
    "        for ii in np.arange(5):\n",
    "            save_dir = os.path.join(output_dir, \n",
    "                                    model_name+'_'+\\\n",
    "                                    xai_name+\\\n",
    "                                    '_class_'+str(ii))\n",
    "            pred_org.append(np.load(os.path.join(save_dir, 'org_pred.npy')))\n",
    "            pred_att.append(np.load(os.path.join(save_dir, 'adv_pred.npy')))\n",
    "            label.append(np.load(os.path.join(save_dir, 'org_labels.npy')))\n",
    "\n",
    "        pred_org = np.concatenate(pred_org, 0)\n",
    "        pred_att = np.concatenate(pred_att, 0)\n",
    "        label = np.concatenate(label, 0)\n",
    "        \n",
    "    else:\n",
    "        save_dir = os.path.join(output_dir, \n",
    "                                model_name+'_'+\\\n",
    "                                xai_name+\\\n",
    "                                '_class_'+str(ii_specific))\n",
    "        pred_org = np.load(os.path.join(save_dir, 'org_pred.npy'))\n",
    "        pred_att = np.load(os.path.join(save_dir, 'adv_pred.npy'))\n",
    "        label = np.load(os.path.join(save_dir, 'org_labels.npy'))\n",
    "    \n",
    "    return pred_org, pred_att, label\n",
    "\n",
    "\n",
    "def load_all_tgt(output_dir, model_name, xai_name, ii_specific=None):\n",
    "    \n",
    "    hm_org, hm_att = [], []\n",
    "    if ii_specific is None:\n",
    "        for ii in np.arange(5):\n",
    "            save_dir = os.path.join(output_dir, \n",
    "                                    model_name+'_'+\\\n",
    "                                    xai_name+\\\n",
    "                                    '_class_'+str(ii))\n",
    "            hm_org.append(np.load(os.path.join(save_dir, 'hm_org.npy')))\n",
    "            hm_att.append(np.load(os.path.join(save_dir, 'hm_att.npy')))\n",
    "\n",
    "        hm_org = np.concatenate(hm_org, 0)\n",
    "        hm_att = np.concatenate(hm_att, 0)\n",
    "        \n",
    "    else:\n",
    "        save_dir = os.path.join(output_dir, \n",
    "                                model_name+'_'+\\\n",
    "                                xai_name+\\\n",
    "                                '_class_'+str(ii_specific))\n",
    "        hm_org = np.load(os.path.join(save_dir, 'hm_org.npy'))\n",
    "        hm_att = np.load(os.path.join(save_dir, 'hm_att.npy'))\n",
    "    \n",
    "    return hm_org, hm_att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d53b36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_classes = len(valid_dataloader.dataset.attr_names)\n",
    "model_list = ['resnet152'] #, 'resnet152']\n",
    "xai_list = ['VanillaBP', 'VanillaBP_Img', 'GradCAM', 'GuidedGradCAM', 'SmoothBP', 'XRAI']\n",
    "pred_att_dir_src = '/data/users/Attack_Attn/save_dir/NatComm/attack_pred'\n",
    "pred_att_dir_tgt = '/data/users/Attack_Attn/save_dir/NatComm/ig_attack_pred'\n",
    "xai_src = 'IntegratedBP'\n",
    "\n",
    "\n",
    "for model_ in model_list:\n",
    "#     model_='densenet121'\n",
    "        print('++++++++++++++++ Model: {} ++++++++++++++++'.format(model_))\n",
    "        for xai_ in xai_list:\n",
    "    # xai_='GradCAM'\n",
    "            print('========= {} ========='.format(xai_))\n",
    "            psc_pred = 0\n",
    "            for class_index in np.arange(num_classes):\n",
    "                # class_index=0\n",
    "\n",
    "                '''load IG pred and compute JSD'''\n",
    "                pred_org, pred_att, label = load_all_src(output_dir=pred_att_dir_src, \n",
    "                                                              model_name=model_, \n",
    "                                                              xai_name=xai_src, \n",
    "                                                              ii_specific=class_index)\n",
    "                '''eval pred attack'''\n",
    "                hm_org, hm_att = load_all_tgt(output_dir=pred_att_dir_tgt, \n",
    "                                              model_name=model_, \n",
    "                                              xai_name=xai_, \n",
    "                                              ii_specific=class_index)\n",
    "\n",
    "                pred_lab_jsd = compute_jsd(pred_org=pred_org, \n",
    "                                           pred_adv=pred_att, \n",
    "                                           class_of_interest=class_index)\n",
    "\n",
    "                pred_hm_jsd = compute_jsd(pred_org=hm_org, \n",
    "                                          pred_adv=hm_att, \n",
    "                                          class_of_interest=class_index)\n",
    "\n",
    "                pred_lab_jsd_np = np.asarray(pred_lab_jsd.numpy())\n",
    "                pred_hm_jsd_np = np.asarray(pred_hm_jsd.numpy())\n",
    "                pred_hm_jsd_np[np.isnan(pred_hm_jsd_np)] = np.nanmean(pred_hm_jsd_np)\n",
    "                psc_pred += pearsonr(pred_lab_jsd_np, pred_hm_jsd_np)[0]/num_classes\n",
    "            print('pred psc: {}'.format(psc_pred))\n",
    "\n",
    "# '''eval expl attack'''\n",
    "# expl_img_, expl_hm_, expl_lab_ = load_all(output_dir=expl_att_dir, \n",
    "#                                          model_name=model_, \n",
    "#                                          xai_name=xai_, \n",
    "#                                          ii_specific=class_index)\n",
    "# att_index = np.where(expl_lab_[2][:,class_index]==1)[0]\n",
    "# expl_lab_jsd = compute_jsd(pred_org=expl_lab_[0][att_index,:], \n",
    "#                            pred_adv=expl_lab_[1][att_index,:], \n",
    "#                            class_of_interest=class_index)\n",
    "# expl_hm_jsd = compute_jsd(pred_org=expl_hm_[0][att_index,:], \n",
    "#                           pred_adv=expl_hm_[1][att_index,:], \n",
    "#                           class_of_interest=class_index)\n",
    "# expl_lab_jsd_np = np.asarray(expl_lab_jsd.numpy())\n",
    "# expl_hm_jsd_np = np.asarray(expl_hm_jsd.numpy())\n",
    "# expl_hm_jsd_np[np.isnan(expl_hm_jsd_np)] = np.nanmean(expl_hm_jsd_np)\n",
    "# psc_expl += pearsonr(expl_lab_jsd_np, expl_hm_jsd_np)[0]/num_classes\n",
    "# print('pred psc: {},   expl psc: {}'.format(psc_pred, psc_expl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8c00b4",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# xai_names = ['VanillaBP']\n",
    "num_classes = len(valid_dataloader.dataset.attr_names)\n",
    "xai_names = ['VanillaBP', 'VanillaBP_Img', 'GradCAM', 'GuidedGradCAM', 'SmoothBP', 'XRAI']\n",
    "model_name = 'resnet152' # 'densenet121'\n",
    "pred_att_dir_tgt = '/data/users/Attack_Attn/save_dir/NatComm/ig_attack_pred'\n",
    "\n",
    "for xai_name in xai_names:\n",
    "    print('-------------------------------- {} --------------------------------'.format(xai_name))\n",
    "    SSIM_hp, MSE_hp = 0,0\n",
    "    for ii in np.arange(num_classes):\n",
    "        ssim_hp, mse_hp = eval_all_metrics(pred_att_dir_tgt,model_name,xai_name,ii)\n",
    "        SSIM_hp += ssim_hp/num_classes\n",
    "        MSE_hp  += mse_hp/num_classes\n",
    "\n",
    "#     eval_all_metrics(model_name, xai_name, None)\n",
    "    print('============= averaged results of {} ============= '.format(xai_name))\n",
    "    print('SSIM_hp: ',SSIM_hp)\n",
    "    print('MSE_hp: ',MSE_hp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f109d166",
   "metadata": {},
   "source": [
    "### Vis-PRED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83942ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 5 xai\n",
    "'''load predictions'''\n",
    "img_index = 124\n",
    "class_index = 1\n",
    "model_name = 'densenet121' #'resnet152'\n",
    "src_xai_name = 'IntegratedBP' #['VanillaBP', 'VanillaBP_Img', 'IntegratedBP', 'GradCAM', 'SmoothBP']\n",
    "src_img_dir = '/data/users/Attack_Attn/save_dir/NatComm/attack_pred/' \n",
    "folder_name = model_name+'_'+src_xai_name+'_class_'+str(class_index)\n",
    "\n",
    "\n",
    "'''load images'''\n",
    "img_org = np.load(os.path.join(src_img_dir, folder_name, 'org_imgs.npy'))\n",
    "img_att = np.load(os.path.join(src_img_dir, folder_name, 'adv_imgs.npy'))\n",
    "pred_org = np.load(os.path.join(src_img_dir, folder_name, 'org_pred.npy'))\n",
    "pred_att = np.load(os.path.join(src_img_dir, folder_name, 'adv_pred.npy'))\n",
    "label = np.load(os.path.join(src_img_dir, folder_name, 'org_labels.npy'))\n",
    "print('label: ', label[img_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93deb7a",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### 5 xai\n",
    "'''load predictions'''\n",
    "img_index = 124\n",
    "class_index = 1\n",
    "model_name = 'densenet121' #'resnet152'\n",
    "src_xai_name = 'IntegratedBP' #['VanillaBP', 'VanillaBP_Img', 'IntegratedBP', 'GradCAM', 'SmoothBP']\n",
    "src_img_dir = '/data/users/Attack_Attn/save_dir/NatComm/attack_pred/' \n",
    "folder_name = model_name+'_'+src_xai_name+'_class_'+str(class_index)\n",
    "\n",
    "\n",
    "'''load images'''\n",
    "img_org = np.load(os.path.join(src_img_dir, folder_name, 'org_imgs.npy'))\n",
    "img_att = np.load(os.path.join(src_img_dir, folder_name, 'adv_imgs.npy'))\n",
    "pred_org = np.load(os.path.join(src_img_dir, folder_name, 'org_pred.npy'))\n",
    "pred_att = np.load(os.path.join(src_img_dir, folder_name, 'adv_pred.npy'))\n",
    "label = np.load(os.path.join(src_img_dir, folder_name, 'org_labels.npy'))\n",
    "print('label: ', label[img_index])\n",
    "\n",
    "\n",
    "'''load heatmap'''\n",
    "for xai_name in ['VanillaBP', 'VanillaBP_Img', 'GradCAM', 'GuidedGradCAM', 'SmoothBP', 'XRAI']:\n",
    "    save_dir = '/data/users/Attack_Attn/save_dir/NatComm/ig_attack_pred/' \n",
    "\n",
    "    folder_name = model_name+'_'+xai_name+'_class_'+str(class_index)\n",
    "    hm_org = np.load(os.path.join(save_dir, folder_name, 'hm_org.npy'))\n",
    "    hm_att = np.load(os.path.join(save_dir, folder_name, 'hm_att.npy'))\n",
    "\n",
    "    save_img_dir = os.path.join(save_dir, 'save_img')\n",
    "    os.makedirs(save_img_dir, exist_ok=True)\n",
    "    print(hm_att.shape, img_att.shape)\n",
    "    \n",
    "    \n",
    "    '''attack'''\n",
    "    output = torch.Tensor(pred_att[img_index])\n",
    "    print(output.sigmoid())\n",
    "    print(label[img_index])\n",
    "\n",
    "    if xai_name == 'GradCAM':\n",
    "        heatmap = hm_att[img_index, 0, :, :]\n",
    "        heatmap = img_norm(heatmap,k=0.88) # norm grad to speial range\n",
    "        cmap = cm.jet_r(1-heatmap)[..., :3]     # color map proj\n",
    "        cmap = img_norm(cmap)\n",
    "    elif xai_name == 'XRAI':\n",
    "        heatmap = hm_att[img_index, 0, :, :]\n",
    "        heatmap = img_norm(heatmap, 1.0) # norm grad to speial range\n",
    "        heatmap[np.where(heatmap<=0.6)] = 0.0\n",
    "        heatmap[np.where(heatmap<=0.6)] = 0.01# XRAI\n",
    "\n",
    "        cmap = cm.jet_r(1-heatmap)[..., :3]     # color map proj\n",
    "        cmap = img_norm(cmap)                     # re-norm to [0,1]\n",
    "        cmap[np.where(cmap<=0.3)] = 0.00\n",
    "    else:\n",
    "        heatmap = hm_att[img_index, 0, :, :]\n",
    "        heatmap = img_norm(heatmap,k=4.7) # norm grad to speial range\n",
    "        cmap = cm.plasma(heatmap)[..., :3]     # color map proj\n",
    "        cmap = img_norm(cmap)\n",
    "\n",
    "    base_img0 = img_att[img_index, 0, :, :]\n",
    "    base_img = np.zeros_like(cmap.squeeze())\n",
    "    base_img[:,:,0], base_img[:,:,1], base_img[:,:,2] = base_img0, base_img0, base_img0\n",
    "\n",
    "\n",
    "    ## load original image\n",
    "    plt.figure(figsize=(6,6))\n",
    "    alpha = .99\n",
    "    htmp_weight = np.zeros_like(cmap.squeeze())\n",
    "    print(htmp_weight.shape)\n",
    "    htmp_weight[:,:,0], htmp_weight[:,:,1], htmp_weight[:,:,2] = heatmap, heatmap, heatmap\n",
    "\n",
    "    img_fused = base_img*(1-htmp_weight) + cmap*alpha*htmp_weight\n",
    "\n",
    "    fig = plt.imshow(img_fused)\n",
    "    fig.axes.get_xaxis().set_visible(False)\n",
    "    fig.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "    save_loc = os.path.join(save_img_dir, folder_name+'_index_'+str(img_index)+'_org.png')\n",
    "    plt.savefig(save_loc, bbox_inches='tight', pad_inches = 0)\n",
    "    \n",
    "    \n",
    "    '''original image'''\n",
    "    output = torch.Tensor(pred_org[img_index])\n",
    "    print(output.sigmoid())\n",
    "\n",
    "    if xai_name == 'GradCAM':\n",
    "        heatmap = hm_org[img_index, 0, :, :]\n",
    "        heatmap = img_norm(heatmap,k=0.88) # norm grad to speial range\n",
    "        cmap = cm.jet_r(1-heatmap)[..., :3]     # color map proj\n",
    "        cmap = img_norm(cmap)\n",
    "    elif xai_name == 'XRAI':\n",
    "        heatmap = hm_org[img_index, 0, :, :]\n",
    "        heatmap = img_norm(heatmap, 1.0) # norm grad to speial range\n",
    "        heatmap[np.where(heatmap<=0.95)] = 0.0\n",
    "        heatmap[np.where(heatmap<=0.6)] = 0.01# XRAI\n",
    "\n",
    "        cmap = cm.jet_r(1-heatmap)[..., :3]     # color map proj\n",
    "        cmap = img_norm(cmap)                     # re-norm to [0,1]\n",
    "        cmap[np.where(cmap<=0.3)] = 0.00\n",
    "    else:\n",
    "        heatmap = hm_org[img_index, 0, :, :]\n",
    "        heatmap = img_norm(heatmap,k=4.7) # norm grad to speial range\n",
    "        cmap = cm.plasma(heatmap)[..., :3]     # color map proj\n",
    "        cmap = img_norm(cmap)\n",
    "\n",
    "    base_img0 = img_org[img_index, 0, :, :]\n",
    "    base_img = np.zeros_like(cmap.squeeze())\n",
    "    base_img[:,:,0], base_img[:,:,1], base_img[:,:,2] = base_img0, base_img0, base_img0\n",
    "\n",
    "\n",
    "    ## load original image\n",
    "    plt.figure(figsize=(6,6))\n",
    "    alpha = .99\n",
    "    htmp_weight = np.zeros_like(cmap.squeeze())\n",
    "    print(htmp_weight.shape)\n",
    "    htmp_weight[:,:,0], htmp_weight[:,:,1], htmp_weight[:,:,2] = heatmap, heatmap, heatmap\n",
    "\n",
    "    img_fused = base_img*(1-htmp_weight) + cmap*alpha*htmp_weight\n",
    "\n",
    "    fig = plt.imshow(img_fused)\n",
    "    fig.axes.get_xaxis().set_visible(False)\n",
    "    fig.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "    save_loc = os.path.join(save_img_dir, folder_name+'_index_'+str(img_index)+'_adv.png')\n",
    "    plt.savefig(save_loc, bbox_inches='tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae866a74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## load original image\n",
    "plt.figure(figsize=(6,6))\n",
    "alpha = .99\n",
    "htmp_weight = np.zeros_like(cmap.squeeze())\n",
    "print(htmp_weight.shape)\n",
    "htmp_weight[:,:,0], htmp_weight[:,:,1], htmp_weight[:,:,2] = heatmap, heatmap, heatmap\n",
    "\n",
    "img_fused = base_img\n",
    "\n",
    "fig = plt.imshow(img_fused)\n",
    "fig.axes.get_xaxis().set_visible(False)\n",
    "fig.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "save_loc = os.path.join(save_img_dir, folder_name+'_index_'+str(img_index)+'_img.png')\n",
    "plt.savefig(save_loc, bbox_inches='tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8124ca2f",
   "metadata": {},
   "source": [
    "## EXPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646bb278",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def load_all(output_dir, model_name, xai_name, ii_specific=None):\n",
    "#     model_name = model_cfgs['src_models'][0]['model_info']['model_name']\n",
    "#     xai_name = model_cfgs['src_models'][0]['exp_method']\n",
    "    img_org, img_att = [], []\n",
    "    pred_org, pred_att, label = [], [], []\n",
    "    hm_org, hm_att = [], []\n",
    "    \n",
    "    if ii_specific is None:\n",
    "        for ii in np.arange(5):\n",
    "            save_dir = os.path.join(output_dir, \n",
    "                                    model_name+'_'+\\\n",
    "                                    xai_name+\\\n",
    "                                    '_class_'+str(ii))\n",
    "            '''load predictions'''\n",
    "            pred_org.append(np.load(os.path.join(save_dir, 'org_pred.npy')))\n",
    "            pred_att.append(np.load(os.path.join(save_dir, 'adv_pred.npy')))\n",
    "            label.append(np.load(os.path.join(save_dir, 'org_labels.npy')))\n",
    "            '''load heat map'''\n",
    "            hm_org.append(np.load(os.path.join(save_dir, 'org_hm.npy')))\n",
    "            hm_att.append(np.load(os.path.join(save_dir, 'adv_hm.npy')))\n",
    "            '''load images'''\n",
    "            img_org.append(np.load(os.path.join(save_dir, 'org_imgs.npy')))\n",
    "            img_att.append(np.load(os.path.join(save_dir, 'adv_imgs.npy')))\n",
    "\n",
    "        pred_org = np.concatenate(pred_org, 0)\n",
    "        pred_att = np.concatenate(pred_att, 0)\n",
    "        label = np.concatenate(label, 0)\n",
    "\n",
    "        hm_org = np.concatenate(hm_org, 0)\n",
    "        hm_att = np.concatenate(hm_att, 0)\n",
    "\n",
    "        img_org = np.concatenate(img_org, 0)\n",
    "        img_att = np.concatenate(img_att, 0)\n",
    "    else:\n",
    "        save_dir = os.path.join(output_dir, \n",
    "                                model_name+'_'+\\\n",
    "                                xai_name+\\\n",
    "                                '_class_'+str(ii_specific))\n",
    "        '''load predictions'''\n",
    "        pred_org = np.load(os.path.join(save_dir, 'org_pred.npy'))\n",
    "        pred_att = np.load(os.path.join(save_dir, 'adv_pred.npy'))\n",
    "        label = np.load(os.path.join(save_dir, 'org_labels.npy'))\n",
    "        '''load heat map'''\n",
    "        hm_org = np.load(os.path.join(save_dir, 'org_hm.npy'))\n",
    "        hm_att = np.load(os.path.join(save_dir, 'adv_hm.npy'))\n",
    "        '''load images'''\n",
    "        img_org = np.load(os.path.join(save_dir, 'org_imgs.npy'))\n",
    "        img_att = np.load(os.path.join(save_dir, 'adv_imgs.npy')) \n",
    "    \n",
    "    return [img_org, img_att], [hm_org, hm_att], [pred_org, pred_att, label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53f91eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "xai_namelist = ['VanillaBP', 'VanillaBP_Img', 'GradCAM', 'GuidedGradCAM', 'SmoothBP', 'XRAI']\n",
    "src_xai = 'IntegratedBP'\n",
    "model_name_list = ['densenet121'] #'resnet152']#, \n",
    "\n",
    "label_dict = {'0': [1., 0., 0., 0., 0.],\n",
    "              '1': [0., 1., 0., 0., 0.],\n",
    "              '2': [0., 0., 1., 0., 0.],\n",
    "              '3': [0., 0., 0., 1., 0.],\n",
    "              '4': [0., 0., 0., 0., 1.]}\n",
    "\n",
    "cfgs['data_dir'] = '/data/users/Attack_Attn/save_dir/NatComm/attack_expl/'\n",
    "cfgs['save_dir'] = '/data/users/Attack_Attn/save_dir/NatComm/ig_attack_expl'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5566d33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in model_name_list:\n",
    "    print('---------------- model: {} ------------------'.format(model_name))\n",
    "    for xai_name in xai_namelist:\n",
    "        print('=============== {} ==============='.format(xai_name))\n",
    "        # xai_name = xai_namelist[0]\n",
    "        '''init model'''\n",
    "        if model_name == 'densenet121':\n",
    "            if xai_name in ['GradCAM', 'GuidedGradCAM']:\n",
    "                dense121_cfgs = {\n",
    "                    'model_info':{\n",
    "                        'model_name': model_name,\n",
    "                        'model_path': '/home/Attack_Attn/ChestXpert/save_dir_multimodel/densenet121_5c/best_checkpoints/checkpoint_9.pt',\n",
    "                    },\n",
    "                    'exp_method': xai_name,\n",
    "                    'exp_cfgs':{\n",
    "                        'target_layer': ['features','denseblock4','denselayer14'],\n",
    "                    }\n",
    "                }\n",
    "            else:\n",
    "                dense121_cfgs = {\n",
    "                    'model_info':{\n",
    "                        'model_name': model_name,\n",
    "                        'model_path': '/home/Attack_Attn/ChestXpert/save_dir_multimodel/densenet121_5c/best_checkpoints/checkpoint_9.pt',\n",
    "                    },\n",
    "                    'exp_method': xai_name,\n",
    "                    'exp_cfgs':{\n",
    "                #         'target_layer': ['features','denseblock4','denselayer14'],\n",
    "                    }\n",
    "                }\n",
    "            model_cfgs = {}\n",
    "            model_cfgs['src_models']=[\n",
    "                dense121_cfgs,\n",
    "            ]\n",
    "            model_cfgs['pretrained'] = False\n",
    "            cfgs['model'] = model_cfgs\n",
    "\n",
    "        elif model_name == 'resnet152':\n",
    "            if xai_name in ['GradCAM', 'GuidedGradCAM']:\n",
    "                res152_cfgs = {\n",
    "                    'model_info':{\n",
    "                        'model_name': model_name,\n",
    "                        'model_path': '/home/Attack_Attn/ChestXpert/save_dir_multimodel/resnet152_5c/best_checkpoints/checkpoint_5.pt',\n",
    "                    },\n",
    "                    'exp_method': xai_name,\n",
    "                    'exp_cfgs':{\n",
    "                        'target_layer': ['layer4','2'],\n",
    "                    }\n",
    "                }\n",
    "            else:\n",
    "                res152_cfgs = {\n",
    "                    'model_info':{\n",
    "                        'model_name': model_name,\n",
    "                        'model_path': '/home/Attack_Attn/ChestXpert/save_dir_multimodel/resnet152_5c/best_checkpoints/checkpoint_5.pt',\n",
    "                    },\n",
    "                    'exp_method': xai_name,\n",
    "                    'exp_cfgs':{\n",
    "    #                     'target_layer': ['layer4','2'],\n",
    "                    }\n",
    "                }\n",
    "            model_cfgs = {}\n",
    "            model_cfgs['src_models']=[\n",
    "                res152_cfgs,\n",
    "            ]\n",
    "            model_cfgs['pretrained'] = False\n",
    "            cfgs['model'] = model_cfgs\n",
    "\n",
    "\n",
    "        source_exp_models = [expmodel_factory(model_cfgs, cfgs) for model_cfgs in cfgs['model']['src_models']]\n",
    "\n",
    "        for ii in np.arange(5): # 5 different classes\n",
    "            # ii = 0\n",
    "            print('++++++ calss number: {} ++++++'.format(ii))\n",
    "            '''load data from IG folder'''\n",
    "            hm_org, hm_att = [], []\n",
    "            img_, _, pred_ = load_all(output_dir=cfgs['data_dir'], \n",
    "                                    model_name=model_cfgs['src_models'][0]['model_info']['model_name'], \n",
    "                                    xai_name=src_xai, \n",
    "                                    ii_specific=ii)\n",
    "            '''select attacked images'''\n",
    "            att_index = np.where(pred_[2][:,ii]==1)[0]\n",
    "            \n",
    "#             image_num, _, _, _ = img_[0][att_index].shape\n",
    "            save_dir = os.path.join(cfgs['save_dir'], \n",
    "                                    model_cfgs['src_models'][0]['model_info']['model_name']+'_'+\\\n",
    "                                    xai_name+\\\n",
    "                                    '_class_'+str(ii))\n",
    "            class_of_interest = label_dict[str(ii)]\n",
    "            os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "            for img_index in att_index: #np.arange(image_num):\n",
    "                print('---- img_index: {} ----'.format(img_index))\n",
    "                img_org = torch.Tensor(img_[0][img_index]).clone().detach()\n",
    "                img_adv = torch.Tensor(img_[1][img_index]).clone().detach()\n",
    "\n",
    "                res_org = [_.cal_exp_map(img_org.to(torch.device(cfgs['device'])).unsqueeze(0), class_of_interest) for _ in source_exp_models]\n",
    "                res_adv = [_.cal_exp_map(img_adv.to(torch.device(cfgs['device'])).unsqueeze(0), class_of_interest) for _ in source_exp_models]\n",
    "\n",
    "                if xai_name == 'XRAI':\n",
    "                    hm_org.append(torch.Tensor(res_org[0][0]).unsqueeze_(0))\n",
    "                    hm_att.append(torch.Tensor(res_adv[0][0]).unsqueeze_(0))\n",
    "                else:\n",
    "                    hm_org.append(res_org[0][0].data.cpu())\n",
    "                    hm_att.append(res_adv[0][0].data.cpu())\n",
    "                del res_org, res_adv\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "            '''save npy images'''\n",
    "            hm_org = torch.cat(hm_org, dim=0).unsqueeze_(1)\n",
    "            hm_att = torch.cat(hm_att, dim=0).unsqueeze_(1)\n",
    "            print(hm_org.shape)\n",
    "\n",
    "            np.save(os.path.join(save_dir, 'hm_org.npy'), hm_org.numpy())\n",
    "            np.save(os.path.join(save_dir, 'hm_att.npy'), hm_att.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dc48b8",
   "metadata": {},
   "source": [
    "### Eval-EXPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d84ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_jsd(pred_org, pred_adv, class_of_interest):\n",
    "    \n",
    "    pred_org, pred_adv = torch.Tensor(pred_org), torch.Tensor(pred_adv)\n",
    "    if len(pred_org.shape) == 4: #image data\n",
    "#         print('image')\n",
    "        prob_org, prob_adv = torch.flatten(pred_org, start_dim=1), torch.flatten(pred_adv, start_dim=1)\n",
    "        prob_mean = torch.clamp((prob_org + prob_adv) / 2., 1e-7, 1).log()\n",
    "#         print(prob_mean.shape)\n",
    "        kld1 = F.kl_div(prob_mean, prob_org, reduction=\"none\").sum(1)\n",
    "        kld2 = F.kl_div(prob_mean, prob_adv, reduction=\"none\").sum(1)\n",
    "    else: # logits data\n",
    "#         print('logits')\n",
    "        prob_org, prob_adv = torch.sigmoid(pred_org), torch.sigmoid(pred_adv)\n",
    "        prob_org_intr, prob_adv_intr = prob_org[:,class_of_interest].unsqueeze(1), prob_adv[:,class_of_interest].unsqueeze(1)\n",
    "\n",
    "        prob_org_binary = torch.cat([prob_org_intr, 1-prob_org_intr], dim=1)\n",
    "        prob_adv_binary = torch.cat([prob_adv_intr, 1-prob_adv_intr], dim=1)\n",
    "        prob_mean = torch.clamp((prob_org_binary + prob_adv_binary) / 2., 1e-7, 1).log()\n",
    "\n",
    "        kld1 = F.kl_div(prob_mean, prob_org_binary, reduction=\"none\").sum(1)\n",
    "        kld2 = F.kl_div(prob_mean, prob_adv_binary, reduction=\"none\").sum(1)\n",
    "    jsd = (kld1 + kld2) * 0.5\n",
    "    return jsd\n",
    "\n",
    "\n",
    "def eval_img_similarity(imgs_1, imgs_2):\n",
    "    assert len(imgs_1.shape) == len(imgs_2.shape) == 3\n",
    "    ssim_vals = []\n",
    "    pcc_vals = []\n",
    "    imgs_1 = batch_img_norm(imgs_1) * 255\n",
    "    imgs_2 = batch_img_norm(imgs_2) * 255\n",
    "    for i in range(imgs_1.shape[0]):\n",
    "        _img1 = imgs_1[i]\n",
    "        _img2 = imgs_2[i]\n",
    "        if np.isnan(_img1.mean()) or np.isnan(_img2.mean()):\n",
    "            print(i)\n",
    "            continue\n",
    "        \n",
    "        # SSIM\n",
    "        _ssim, _ = ssim(_img1, _img2, data_range=255, full=True, multichannel=False)\n",
    "        ssim_vals.append(_ssim)\n",
    "        \n",
    "        # PCC\n",
    "        _pcc = pearsonr(_img1.reshape(-1), _img2.reshape(-1))[0]\n",
    "        pcc_vals.append(_pcc)\n",
    "    \n",
    "    # MSE\n",
    "    mse_vals = np.nanmean(((imgs_1/255 - imgs_2/255)**2).mean(-1))\n",
    "    return {\n",
    "        'ssim': np.asarray(ssim_vals),\n",
    "        'mse': mse_vals,\n",
    "        'pcc': np.asarray(pcc_vals),\n",
    "    }\n",
    "\n",
    "\n",
    "def eval_all_metrics(output_dir, model_name, xai_name, ii_specific=None):\n",
    "    hm_org, hm_att = load_all_tgt(output_dir, model_name, xai_name, ii_specific) \n",
    "    print(hm_org.shape, hm_att.shape)\n",
    "    if ii_specific is None:\n",
    "        print('+++++++++++++++++++++ all images ++++++++++++++++++++')\n",
    "    else:\n",
    "        print('+++++++++++++++++++++ class {} ++++++++++++++++++++'.format(ii_specific))\n",
    "    \n",
    "    print('=== Heat Map ===')\n",
    "    attack_target_maps = np.zeros_like(hm_org[:,0,:,:])\n",
    "    attack_target_maps[:, 130:190, 380:440] = 1.0/3600 # binary mask\n",
    "    res_org = eval_img_similarity(hm_org[:,0,:,:], hm_att[:,0,:,:])\n",
    "    res_tgt = eval_img_similarity(attack_target_maps, hm_att[:,0,:,:])\n",
    "    \n",
    "    for _k in res_org.keys():\n",
    "#         print(res_org[_k].shape)\n",
    "        _v = np.nanmean(res_org[_k])\n",
    "#         print(_k, _v)\n",
    "        if _k == 'ssim': ssim_hp_org = _v\n",
    "        if _k == 'mse': mse_hp_org = _v\n",
    "    \n",
    "    for _k in res_tgt.keys():\n",
    "        _v = np.nanmean(res_tgt[_k])\n",
    "#         print(_k, _v)\n",
    "        if _k == 'ssim': ssim_hp_tgt = _v\n",
    "        if _k == 'mse': mse_hp_tgt = _v\n",
    "            \n",
    "    return ssim_hp_org, ssim_hp_tgt, mse_hp_org, mse_hp_tgt\n",
    "\n",
    "\n",
    "\n",
    "def load_all_src(output_dir, model_name, xai_name, ii_specific=None):\n",
    "    '''load predictions'''\n",
    "    hm_org, hm_att = [], []\n",
    "    if ii_specific is None:\n",
    "        for ii in np.arange(5):\n",
    "            save_dir = os.path.join(output_dir, \n",
    "                                    model_name+'_'+\\\n",
    "                                    xai_name+\\\n",
    "                                    '_class_'+str(ii))\n",
    "            pred_org.append(np.load(os.path.join(save_dir, 'org_pred.npy')))\n",
    "            pred_att.append(np.load(os.path.join(save_dir, 'adv_pred.npy')))\n",
    "            label.append(np.load(os.path.join(save_dir, 'org_labels.npy')))\n",
    "\n",
    "        pred_org = np.concatenate(pred_org, 0)\n",
    "        pred_att = np.concatenate(pred_att, 0)\n",
    "        label = np.concatenate(label, 0)\n",
    "        \n",
    "    else:\n",
    "        save_dir = os.path.join(output_dir, \n",
    "                                model_name+'_'+\\\n",
    "                                xai_name+\\\n",
    "                                '_class_'+str(ii_specific))\n",
    "        pred_org = np.load(os.path.join(save_dir, 'org_pred.npy'))\n",
    "        pred_att = np.load(os.path.join(save_dir, 'adv_pred.npy'))\n",
    "        label = np.load(os.path.join(save_dir, 'org_labels.npy'))\n",
    "        \n",
    "        '''select attacked images'''\n",
    "        att_index = np.where(label[:,ii_specific]==1)[0]\n",
    "        pred_org = pred_org[att_index]\n",
    "        pred_att = pred_att[att_index]\n",
    "        label = label[att_index]\n",
    "    \n",
    "    return pred_org, pred_att, label\n",
    "\n",
    "\n",
    "def load_all_tgt(output_dir, model_name, xai_name, ii_specific=None):\n",
    "    \n",
    "    hm_org, hm_att = [], []\n",
    "    if ii_specific is None:\n",
    "        for ii in np.arange(5):\n",
    "            save_dir = os.path.join(output_dir, \n",
    "                                    model_name+'_'+\\\n",
    "                                    xai_name+\\\n",
    "                                    '_class_'+str(ii))\n",
    "            hm_org.append(np.load(os.path.join(save_dir, 'hm_org.npy')))\n",
    "            hm_att.append(np.load(os.path.join(save_dir, 'hm_att.npy')))\n",
    "\n",
    "        hm_org = np.concatenate(hm_org, 0)\n",
    "        hm_att = np.concatenate(hm_att, 0)\n",
    "        \n",
    "    else:\n",
    "        save_dir = os.path.join(output_dir, \n",
    "                                model_name+'_'+\\\n",
    "                                xai_name+\\\n",
    "                                '_class_'+str(ii_specific))\n",
    "        hm_org = np.load(os.path.join(save_dir, 'hm_org.npy'))\n",
    "        hm_att = np.load(os.path.join(save_dir, 'hm_att.npy'))\n",
    "    \n",
    "    return hm_org, hm_att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef4b0ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# xai_names = ['VanillaBP']\n",
    "num_classes = len(valid_dataloader.dataset.attr_names)\n",
    "xai_names = ['VanillaBP', 'VanillaBP_Img', 'GradCAM', 'GuidedGradCAM', 'SmoothBP', 'XRAI']\n",
    "model_name_list = ['resnet152', 'densenet121']\n",
    "pred_att_dir_tgt = '/data/users/Attack_Attn/save_dir/NatComm/ig_attack_expl'\n",
    "\n",
    "for model_name in model_name_list:\n",
    "    print('Model: ', model_name)\n",
    "    for xai_name in xai_names:\n",
    "        print('-------------------------------- {} --------------------------------'.format(xai_name))\n",
    "        SSIM_hp_org, SSIM_hp_tgt, MSE_hp_org, MSE_hp_tgt = 0,0,0,0\n",
    "        for ii in np.arange(num_classes):\n",
    "            ssim_hp_org, ssim_hp_tgt, mse_hp_org, mse_hp_tgt = eval_all_metrics(pred_att_dir_tgt,model_name,xai_name,ii)\n",
    "            SSIM_hp_org += ssim_hp_org/num_classes\n",
    "            SSIM_hp_tgt += ssim_hp_tgt/num_classes\n",
    "            MSE_hp_org  += mse_hp_org/num_classes\n",
    "            MSE_hp_tgt  += mse_hp_tgt/num_classes\n",
    "\n",
    "    #     eval_all_metrics(model_name, xai_name, None)\n",
    "        print('============= averaged results of {} ============= '.format(xai_name))\n",
    "        print('SSIM origin: ',SSIM_hp_org)\n",
    "        print('SSIM target: ',SSIM_hp_tgt)\n",
    "        print('MSE origin: ',MSE_hp_org)\n",
    "        print('MSE target: ',MSE_hp_tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d182b42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(valid_dataloader.dataset.attr_names)\n",
    "model_list = ['resnet152', 'densenet121']\n",
    "xai_list = ['VanillaBP', 'VanillaBP_Img', 'GradCAM', 'GuidedGradCAM', 'SmoothBP', 'XRAI']\n",
    "pred_att_dir_src = '/data/users/Attack_Attn/save_dir/NatComm/attack_expl'\n",
    "pred_att_dir_tgt = '/data/users/Attack_Attn/save_dir/NatComm/ig_attack_expl'\n",
    "xai_src = 'IntegratedBP'\n",
    "\n",
    "\n",
    "for model_ in model_list:\n",
    "#     model_='densenet121'\n",
    "        print('++++++++++++++++ Model: {} ++++++++++++++++'.format(model_))\n",
    "        for xai_ in xai_list:\n",
    "    # xai_='GradCAM'\n",
    "            print('========= {} ========='.format(xai_))\n",
    "            psc_pred = 0\n",
    "            for class_index in np.arange(num_classes):\n",
    "                # class_index=0\n",
    "\n",
    "                '''load IG pred and compute JSD'''\n",
    "                pred_org, pred_att, label = load_all_src(output_dir=pred_att_dir_src, \n",
    "                                                         model_name=model_, \n",
    "                                                         xai_name=xai_src, \n",
    "                                                         ii_specific=class_index)\n",
    "                '''eval pred attack'''\n",
    "                hm_org, hm_att = load_all_tgt(output_dir=pred_att_dir_tgt, \n",
    "                                              model_name=model_, \n",
    "                                              xai_name=xai_, \n",
    "                                              ii_specific=class_index)\n",
    "\n",
    "                pred_lab_jsd = compute_jsd(pred_org=pred_org, \n",
    "                                           pred_adv=pred_att, \n",
    "                                           class_of_interest=class_index)\n",
    "\n",
    "                pred_hm_jsd = compute_jsd(pred_org=hm_org, \n",
    "                                          pred_adv=hm_att, \n",
    "                                          class_of_interest=class_index)\n",
    "\n",
    "                pred_lab_jsd_np = np.asarray(pred_lab_jsd.numpy())\n",
    "                pred_hm_jsd_np = np.asarray(pred_hm_jsd.numpy())\n",
    "                pred_hm_jsd_np[np.isnan(pred_hm_jsd_np)] = np.nanmean(pred_hm_jsd_np)\n",
    "                psc_pred += pearsonr(pred_lab_jsd_np, pred_hm_jsd_np)[0]/num_classes\n",
    "            print('pred psc: {}'.format(psc_pred))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe6d425",
   "metadata": {},
   "source": [
    "### Vis-EXPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d851d5",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### 5 xai\n",
    "'''load predictions'''\n",
    "img_index = 16\n",
    "class_index = 1\n",
    "model_name = 'densenet121' #'resnet152'\n",
    "src_xai_name = 'IntegratedBP' #['VanillaBP', 'VanillaBP_Img', 'IntegratedBP', 'GradCAM', 'SmoothBP']\n",
    "src_img_dir = '/data/users/Attack_Attn/save_dir/NatComm/attack_expl/' \n",
    "folder_name = model_name+'_'+src_xai_name+'_class_'+str(class_index)\n",
    "\n",
    "\n",
    "'''load images'''\n",
    "img_org = np.load(os.path.join(src_img_dir, folder_name, 'org_imgs.npy'))\n",
    "img_att = np.load(os.path.join(src_img_dir, folder_name, 'adv_imgs.npy'))\n",
    "pred_org = np.load(os.path.join(src_img_dir, folder_name, 'org_pred.npy'))\n",
    "pred_att = np.load(os.path.join(src_img_dir, folder_name, 'adv_pred.npy'))\n",
    "label = np.load(os.path.join(src_img_dir, folder_name, 'org_labels.npy'))\n",
    "\n",
    "'''select attacked images'''\n",
    "att_index = np.where(label[:,class_index]==1)[0]\n",
    "img_org = img_org[att_index]\n",
    "img_att = img_att[att_index] \n",
    "pred_org = pred_org[att_index]\n",
    "pred_att = pred_att[att_index]\n",
    "label = label[att_index]\n",
    "# print(img_org.shape, img_att.shape)\n",
    "\n",
    "# print('label: ', label[img_index])\n",
    "\n",
    "'''load heatmap'''\n",
    "for xai_name in ['VanillaBP', 'VanillaBP_Img', 'GradCAM', 'GuidedGradCAM', 'SmoothBP', 'XRAI']:\n",
    "    save_dir = '/data/users/Attack_Attn/save_dir/NatComm/ig_attack_expl/' \n",
    "\n",
    "    folder_name = model_name+'_'+xai_name+'_class_'+str(class_index)\n",
    "    hm_org = np.load(os.path.join(save_dir, folder_name, 'hm_org.npy'))\n",
    "    hm_att = np.load(os.path.join(save_dir, folder_name, 'hm_att.npy'))\n",
    "\n",
    "    save_img_dir = os.path.join(save_dir, 'save_img')\n",
    "    os.makedirs(save_img_dir, exist_ok=True)\n",
    "#     print(hm_att.shape, img_att.shape)\n",
    "    \n",
    "    '''attack'''\n",
    "    output = torch.Tensor(pred_att[img_index])\n",
    "    print(output.sigmoid())\n",
    "    print(label[img_index])\n",
    "\n",
    "    if xai_name == 'GradCAM':\n",
    "        heatmap = hm_att[img_index, 0, :, :]\n",
    "        heatmap = img_norm(heatmap,k=0.88) # norm grad to speial range\n",
    "        cmap = cm.jet_r(1-heatmap)[..., :3]     # color map proj\n",
    "        cmap = img_norm(cmap)\n",
    "    elif xai_name == 'XRAI':\n",
    "        heatmap = hm_att[img_index, 0, :, :]\n",
    "        heatmap = img_norm(heatmap, 1.0) # norm grad to speial range\n",
    "        heatmap[np.where(heatmap<=0.98)] = 0.0\n",
    "        heatmap[np.where(heatmap<=0.7)] = 0.01# XRAI\n",
    "\n",
    "        cmap = cm.jet_r(1-heatmap)[..., :3]     # color map proj\n",
    "        cmap = img_norm(cmap)                     # re-norm to [0,1]\n",
    "        cmap[np.where(cmap<=0.3)] = 0.00\n",
    "    else:\n",
    "        heatmap = hm_att[img_index, 0, :, :]\n",
    "        heatmap = img_norm(heatmap,k=4.7) # norm grad to speial range\n",
    "        cmap = cm.plasma(heatmap)[..., :3]     # color map proj\n",
    "        cmap = img_norm(cmap)\n",
    "\n",
    "    base_img0 = img_att[img_index, 0, :, :]\n",
    "    base_img = np.zeros_like(cmap.squeeze())\n",
    "    base_img[:,:,0], base_img[:,:,1], base_img[:,:,2] = base_img0, base_img0, base_img0\n",
    "\n",
    "\n",
    "    ## load original image\n",
    "    plt.figure(figsize=(6,6))\n",
    "    alpha = .99\n",
    "    htmp_weight = np.zeros_like(cmap.squeeze())\n",
    "    print(htmp_weight.shape)\n",
    "    htmp_weight[:,:,0], htmp_weight[:,:,1], htmp_weight[:,:,2] = heatmap, heatmap, heatmap\n",
    "\n",
    "    img_fused = base_img*(1-htmp_weight) + cmap*alpha*htmp_weight\n",
    "\n",
    "    fig = plt.imshow(img_fused)\n",
    "    fig.axes.get_xaxis().set_visible(False)\n",
    "    fig.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "    save_loc = os.path.join(save_img_dir, folder_name+'_index_'+str(img_index)+'_org.png')\n",
    "    plt.savefig(save_loc, bbox_inches='tight', pad_inches = 0)\n",
    "    \n",
    "    \n",
    "    '''original image'''\n",
    "    output = torch.Tensor(pred_org[img_index])\n",
    "    print(output.sigmoid())\n",
    "\n",
    "    if xai_name == 'GradCAM':\n",
    "        heatmap = hm_org[img_index, 0, :, :]\n",
    "        heatmap = img_norm(heatmap,k=0.88) # norm grad to speial range\n",
    "        cmap = cm.jet_r(1-heatmap)[..., :3]     # color map proj\n",
    "        cmap = img_norm(cmap)\n",
    "    elif xai_name == 'XRAI':\n",
    "        heatmap = hm_org[img_index, 0, :, :]\n",
    "        heatmap = img_norm(heatmap, 1.0) # norm grad to speial range\n",
    "        heatmap[np.where(heatmap<=0.82)] = 0.0\n",
    "        heatmap[np.where(heatmap<=0.7)] = 0.01# XRAI\n",
    "\n",
    "        cmap = cm.jet_r(1-heatmap)[..., :3]     # color map proj\n",
    "        cmap = img_norm(cmap)                     # re-norm to [0,1]\n",
    "        cmap[np.where(cmap<=0.3)] = 0.00\n",
    "    else:\n",
    "        heatmap = hm_org[img_index, 0, :, :]\n",
    "        heatmap = img_norm(heatmap,k=4.7) # norm grad to speial range\n",
    "        cmap = cm.plasma(heatmap)[..., :3]     # color map proj\n",
    "        cmap = img_norm(cmap)\n",
    "\n",
    "    base_img0 = img_org[img_index, 0, :, :]\n",
    "    base_img = np.zeros_like(cmap.squeeze())\n",
    "    base_img[:,:,0], base_img[:,:,1], base_img[:,:,2] = base_img0, base_img0, base_img0\n",
    "\n",
    "\n",
    "    ## load original image\n",
    "    plt.figure(figsize=(6,6))\n",
    "    alpha = .99\n",
    "    htmp_weight = np.zeros_like(cmap.squeeze())\n",
    "    print(htmp_weight.shape)\n",
    "    htmp_weight[:,:,0], htmp_weight[:,:,1], htmp_weight[:,:,2] = heatmap, heatmap, heatmap\n",
    "\n",
    "    img_fused = base_img*(1-htmp_weight) + cmap*alpha*htmp_weight\n",
    "\n",
    "    fig = plt.imshow(img_fused)\n",
    "    fig.axes.get_xaxis().set_visible(False)\n",
    "    fig.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "    save_loc = os.path.join(save_img_dir, folder_name+'_index_'+str(img_index)+'_adv.png')\n",
    "    plt.savefig(save_loc, bbox_inches='tight', pad_inches = 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "396.431px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
